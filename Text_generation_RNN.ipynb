{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de texto con RNN (encoder-decoder) en TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Mean\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos y extraemos el texto de Don Quijote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gutenberg.org/\n",
    "url_don_quijote = \"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "path_to_file = tf.keras.utils.get_file('don_quijote.txt', url_don_quijote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto principal extraído. Longitud: 2110726\n",
      "Fragmento inicial:\n",
      " El ingenioso hidalgo don Quijote de la Mancha\n",
      "\n",
      "\n",
      "\n",
      "por Miguel de Cervantes Saavedra\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "\n",
      "\n",
      "  \n",
      "Tasa\n",
      "\n",
      "  \n",
      "Testimonio de las erratas\n",
      "\n",
      "  \n",
      "El Rey\n",
      "\n",
      "  \n",
      "Al Duque de Béjar\n",
      "\n",
      "  \n",
      "Prólogo\n",
      "\n",
      "  \n",
      "Al libro de don Quijote de la Mancha\n",
      "\n",
      "\n",
      "\n",
      "Que trata de la condición y ejercicio del famoso\n",
      "hidalgo don Quijote de la Mancha\n",
      "\n",
      "Que trata de la primera salida que de su tierra hizo\n",
      "el ingenioso don Quijote\n",
      "\n",
      "Donde se cuenta la graciosa manera que tuvo don\n",
      "Quijote en armarse caballero\n",
      "...\n",
      "Fragmento final:\n",
      " en éstos como en los estraños reinos''. Y con esto cumplirás\n",
      "con tu cristiana profesión, aconsejando bien a quien mal te quiere, y yo\n",
      "quedaré satisfecho y ufano de haber sido el primero que gozó el fruto de\n",
      "sus escritos enteramente, como deseaba, pues no ha sido otro mi deseo que\n",
      "poner en aborrecimiento de los hombres las fingidas y disparatadas\n",
      "historias de los libros de caballerías, que, por las de mi verdadero don\n",
      "Quijote, van ya tropezando, y han de caer del todo, sin duda alguna. Vale.\n",
      "\n",
      "Fin\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK DON QUIJOTE ***\"\n",
    "end_marker   = \"*** END OF THE PROJECT GUTENBERG EBOOK DON QUIJOTE ***\"\n",
    "\n",
    "start_index = full_text.find(start_marker)\n",
    "end_index   = full_text.find(end_marker)\n",
    "\n",
    "if start_index == -1 or end_index == -1:\n",
    "    # Si no se encuentran los marcadores:\n",
    "    print(\"No se han encontrado los marcadores en el texto. Revisa si la URL o el texto han cambiado.\")\n",
    "else:\n",
    "    # Extrae solo la parte que nos interesa\n",
    "    # Sumamos la longitud de start_marker para no quedarnos con la línea entera\n",
    "    main_text = full_text[start_index + len(start_marker):end_index]\n",
    "\n",
    "    # Limpiamos espacios o saltos de línea excesivos al inicio y final\n",
    "    main_text = main_text.strip()\n",
    "\n",
    "    print(\"Texto principal extraído. Longitud:\", len(main_text))\n",
    "    print(\"Fragmento inicial:\\n\", main_text[:500])\n",
    "    print(\"...\\nFragmento final:\\n\", main_text[-500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el vocabulario de caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos a extraer todos los caracteres únicos del texto. Esto nos permitirá construir un vocabulario con el que podamos asignar un ID numérico a cada carácter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres únicos en el Quijote: 92\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', '«', '»', '¿', 'Á', 'É', 'Í', 'Ñ', 'Ó', 'Ú', 'à', 'á', 'é', 'í', 'ï', 'ñ', 'ó', 'ù', 'ú', 'ü', '—']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(main_text))\n",
    "print(\"Caracteres únicos en el Quijote:\", len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapear caracteres a enteros (y viceversa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorización de caracteres con `StringLookup`\n",
    "\n",
    "Antes de entrenar el modelo, necesitamos transformar el texto en una forma que pueda ser procesada por una red neuronal. Para ello, utilizamos la capa [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup) de Keras, que convierte caracteres en IDs numéricos y viceversa.\n",
    "\n",
    "Concretamente:\n",
    "\n",
    "- `ids_from_chars`: mapea cada carácter del texto a un número entero.\n",
    "- `chars_from_ids`: hace la operación inversa, recuperando el carácter original a partir del ID.\n",
    "\n",
    "Este mapeo es fundamental para:\n",
    "- Codificar el texto como secuencias numéricas que puedan ser entendidas por el modelo.\n",
    "- Convertir las predicciones del modelo (que serán también IDs) de vuelta a texto legible.\n",
    "\n",
    "##### ¿Qué es `[UNK]`?\n",
    "\n",
    "Cuando usamos `StringLookup`, cualquier carácter desconocido que no esté en el vocabulario se asigna por defecto al token `[UNK]` (abreviación de “unknown”). Esto permite manejar entradas inesperadas o erróneas sin que el modelo falle, aunque lo ideal es que el vocabulario contenga todos los caracteres relevantes del texto.\n",
    "\n",
    "En este caso, como extraemos los caracteres únicos directamente del texto original del Quijote, **el vocabulario está perfectamente alineado con los datos**, por lo que no deberíamos ver `[UNK]` en la práctica. Aun así, la capa lo reserva por defecto como una opción de seguridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743934365.966342    5215 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Crear el mapeo de caracteres a IDs\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None\n",
    ")\n",
    "\n",
    "# Crear el mapeo inverso de IDs a caracteres\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
    ")\n",
    "\n",
    "# Función para convertir una secuencia de IDs a texto\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(keras.src.layers.preprocessing.string_lookup.StringLookup,\n",
       " keras.src.layers.preprocessing.string_lookup.StringLookup)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estas capas son muy útiles porque permiten mantener la trazabilidad entre el texto original y las representaciones numéricas que procesará el modelo.\n",
    "type(chars_from_ids), type(ids_from_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualización del mapeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar que la codificación y decodificación funcionan correctamente, mostramos un ejemplo sencillo.\n",
    "\n",
    "Esto nos permite ver que:\n",
    "\n",
    "- El texto `\"Don Quijote\"` se convierte en una secuencia de enteros.\n",
    "- Esa secuencia puede ser transformada de nuevo en el texto original, garantizando que el mapeo es bidireccional y preciso.\n",
    "\n",
    "Esta visualización es útil como prueba de validación antes de continuar con el preprocesamiento del corpus completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres: [b'D' b'o' b'n' b' ' b'Q' b'u' b'i' b'j' b'o' b't' b'e']\n",
      "IDs: [25 61 60  2 37 67 56 57 61 66 52]\n",
      "Reconstruido: [b'D' b'o' b'n' b' ' b'Q' b'u' b'i' b'j' b'o' b't' b'e']\n"
     ]
    }
   ],
   "source": [
    "example_chars = tf.constant(list(\"Don Quijote\"))\n",
    "char_ids = ids_from_chars(example_chars)\n",
    "reconstructed = chars_from_ids(char_ids)\n",
    "\n",
    "print(\"Caracteres:\", example_chars.numpy())\n",
    "print(\"IDs:\", char_ids.numpy())\n",
    "print(\"Reconstruido:\", reconstructed.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversión del texto completo a IDs y verificación visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos ahora `ids_from_chars` a todo el texto para convertir cada carácter en un ID numérico, generando así la secuencia completa que servirá como entrada para el modelo.\n",
    "\n",
    "Esto transforma el corpus textual en una serie de números enteros que codifican el texto carácter por carácter, preservando el estilo y la estructura.\n",
    "\n",
    "- Verificación\n",
    "\n",
    "    Para asegurarnos de que esta conversión es correcta:\n",
    "\n",
    "    - Mostramos los primeros 40 caracteres del texto y sus correspondientes IDs.\n",
    "    - Reconstruimos esos IDs de nuevo a texto usando `chars_from_ids`.\n",
    "    - Visualizamos ambos (carácter e ID) en una tabla para confirmar que el proceso de codificación y decodificación es simétrico.\n",
    "\n",
    "    Esto es crucial para garantizar que el modelo reciba los datos en el formato correcto, y que luego podamos interpretar sus predicciones sin ambigüedades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· Primeros 10 IDs: [26 58  2 56 60 54 52 60 56 61 65 61  2 55 56 51 48 58 54 61  2 51 61 60\n",
      "  2 37 67 56 57 61 66 52  2 51 52  2 58 48  2 33]\n",
      "\n",
      "· Reconstrucción: El ingenioso hidalgo don Quijote de la M\n"
     ]
    }
   ],
   "source": [
    "# Convertimos el texto completo a una secuencia de IDs (enteros)\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(main_text, input_encoding=\"UTF-8\"))\n",
    "\n",
    "# Verificación rápida\n",
    "print(\"· Primeros 10 IDs:\", all_ids[:40].numpy())\n",
    "print(\"\\n· Reconstrucción:\", text_from_ids(all_ids[:40]).numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carácter</th>\n",
       "      <td>E</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1  2   3   4   5   6   7   8   9   ...  30  31 32  33  34 35  \\\n",
       "Carácter   E   l      i   n   g   e   n   i   o  ...   t   e      d   e      \n",
       "ID        26  58  2  56  60  54  52  60  56  61  ...  66  52  2  51  52  2   \n",
       "\n",
       "          36  37 38  39  \n",
       "Carácter   l   a      M  \n",
       "ID        58  48  2  33  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Carácter\": list(main_text[:40]),\n",
    "    \"ID\": all_ids[:40].numpy()\n",
    "})\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear secuencias a partir del texto vectorizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos transformado el texto completo en una secuencia de IDs (`all_ids`).  \n",
    "Ahora necesitamos dividir esa secuencia larga en **subsecuencias de longitud fija**, que representarán:\n",
    "\n",
    "- El **input** que le damos al modelo\n",
    "- Y el **target** que esperamos que prediga (el siguiente carácter tras cada input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo se hace?\n",
    "\n",
    "1. Elegimos un valor de `seq_length`, por ejemplo 250.  \n",
    "2. Tomamos fragmentos consecutivos del tipo:\n",
    "   - Input: los primeros 250 caracteres\n",
    "   - Target: los mismos 250 desplazados una posición hacia adelante\n",
    "\n",
    "    Ejemplo simplificado con `seq_length = 5`:\n",
    "\n",
    "    | Input IDs     | Target IDs    |\n",
    "    |---------------|---------------|\n",
    "    | [1, 2, 3, 4, 5] | [2, 3, 4, 5, 6] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparación con `tf.data.Dataset`\n",
    "\n",
    "- TensorFlow nos permite convertir directamente la secuencia de enteros (`all_ids`) en un dataset eficiente usando `tf.data.Dataset.from_tensor_slices()`.  \n",
    "- Luego agrupamos por ventanas de longitud `seq_length + 1`, y usamos una función auxiliar para separar cada fragmento en `(input, target)`.\n",
    "\n",
    "Al final, barajamos y preparamos el dataset en batches para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Input (primeros 50 caracteres):\n",
      "IDs del input: [26 58  2 56 60 54 52 60 56 61]\n",
      "'El ingenioso hidalgo don Quijote de la Mancha\\n\\n\\n\\np'\n",
      "\n",
      "🔸 Target (primeros 50 caracteres):\n",
      "IDs del target: [58  2 56 60 54 52 60 56 61 65]\n",
      "'l ingenioso hidalgo don Quijote de la Mancha\\n\\n\\n\\npo'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:12:46.629537: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Longitud de cada secuencia de entrada (puedes cambiarlo)\n",
    "seq_length = 250\n",
    "\n",
    "# Dividimos la secuencia en segmentos de longitud seq_length + 1\n",
    "sequences = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "sequences = sequences.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# Función que separa input y target\n",
    "def split_input_target(seq):\n",
    "    input_seq = seq[:-1]   # todos excepto el último\n",
    "    target_seq = seq[1:]   # todos excepto el primero\n",
    "    return input_seq, target_seq\n",
    "\n",
    "# Aplicamos la transformación\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Verificación más clara y acotada\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    input_text = text_from_ids(input_example).numpy().decode(\"utf-8\")\n",
    "    target_text = text_from_ids(target_example).numpy().decode(\"utf-8\")\n",
    "\n",
    "    print(\"🔹 Input (primeros 50 caracteres):\")\n",
    "    print(\"IDs del input:\", input_example[:10].numpy())\n",
    "    print(repr(input_text[:50]))\n",
    "    print(\"\\n🔸 Target (primeros 50 caracteres):\")\n",
    "    print(\"IDs del target:\", target_example[:10].numpy())\n",
    "    print(repr(target_text[:50]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el dataset para entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez generadas las secuencias `(input, target)`, es hora de preparar el dataset para que pueda ser usado durante el entrenamiento del modelo de forma eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué pasos seguimos?**\n",
    "\n",
    "1. **Mezclar (shuffle)**  \n",
    "    - Esto evita que el modelo aprenda dependencias artificiales del orden original del texto.\n",
    "    - Usamos un búfer grande para garantizar una mezcla adecuada (por ejemplo, 10.000 elementos).\n",
    "\n",
    "2. **Agrupar en batches**  \n",
    "    - Procesamos varios ejemplos a la vez durante el entrenamiento.\n",
    "    - Esto acelera el proceso y permite que el modelo aprenda de patrones en paralelo.\n",
    "\n",
    "3. **Prefetching**  \n",
    "    - Prepara los siguientes batches mientras se entrena con los actuales.\n",
    "    - Mejora el rendimiento y reduce el tiempo de espera entre pasos de entrenamiento.\n",
    "\n",
    "Con esta preparación, el dataset estará optimizado tanto en términos de memoria como de velocidad de procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de batches: 65\n",
      "Shape del input: (128, 250)\n",
      "Shape del target: (128, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:12:47.652088: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Mezclamos, agrupamos en batches y activamos prefetching\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validación\n",
    "total_batches = dataset.cardinality().numpy()\n",
    "print(\"Total de batches:\", total_batches)\n",
    "val_batches = total_batches // 10  # 10% para validación\n",
    "val_dataset = dataset.take(val_batches)\n",
    "train_dataset = dataset.skip(val_batches)\n",
    "\n",
    "# Verificamos la estructura final del dataset\n",
    "for input_batch, target_batch in dataset.take(1):\n",
    "    print(\"Shape del input:\", input_batch.shape)\n",
    "    print(\"Shape del target:\", target_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el modelo RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ya tenemos los datos listos. Ahora construiremos el modelo neuronal que será capaz de **predecir el siguiente carácter** dado un fragmento previo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura utilizada\n",
    "\n",
    "Definimos el modelo como una subclase de `tf.keras.Model`. Está compuesto por tres capas principales:\n",
    "\n",
    "1. **`Embedding`**  \n",
    "   Convierte IDs de caracteres en vectores densos de dimensión fija. Esto permite al modelo aprender representaciones útiles de cada carácter.\n",
    "\n",
    "2. **`GRU` (Gated Recurrent Unit)**  \n",
    "   Capa recurrente que captura relaciones temporales.  \n",
    "   La configuramos con `return_sequences=True` y `return_state=True` para que devuelva toda la secuencia de salidas y el estado final (cuando lo necesitemos).\n",
    "\n",
    "3. **`Dense`**  \n",
    "   Capa de salida que produce una predicción de probabilidad para cada carácter del vocabulario.\n",
    "\n",
    "### Hiperparámetros\n",
    "\n",
    "- `vocab_size`: cantidad total de caracteres únicos que reconoce el modelo.\n",
    "- `embedding_dim`: dimensión de los vectores de embedding.\n",
    "- `rnn_units`: número de neuronas en la GRU.\n",
    "\n",
    "Esta arquitectura, aunque sencilla, es adecuada para generar texto en el estilo del Quijote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del input: (128, 250)\n",
      "Shape del output: (128, 250, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743934369.957781    5673 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Hiperparámetros del modelo\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Número total de caracteres únicos (vocabulario del modelo)\n",
    "# Incluye el token especial [UNK] usado por StringLookup\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# Dimensión de los vectores de embedding (puedes ajustar)\n",
    "embedding_dim = 128\n",
    "\n",
    "# Número de unidades en la GRU (tamaño del estado oculto)\n",
    "rnn_units = 1250 \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Definición del modelo como subclase de tf.keras.Model\n",
    "# ------------------------------------------------------------\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__()  # Inicializa la clase base tf.keras.Model\n",
    "\n",
    "        # Capa de Embedding: transforma cada ID en un vector denso\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        # Capa GRU: procesa secuencias manteniendo memoria a lo largo del tiempo\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            units=rnn_units,\n",
    "            return_sequences=True,  # Devuelve salida en cada paso\n",
    "            return_state=True       # También devuelve el estado final\n",
    "        )\n",
    "\n",
    "        # Capa densa final: proyecta la salida de la GRU a un vector del tamaño del vocabulario\n",
    "        self.dense = tf.keras.layers.Dense(units=vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        # 2. Procesamiento con GRU\n",
    "        outputs = self.gru(x, initial_state=states, training=training)\n",
    "        if return_state:\n",
    "            x, states = outputs  # Desempaqueta (output_sequence, estado_final)\n",
    "            x = self.dense(x, training=training)\n",
    "            return x, states\n",
    "        else:\n",
    "            x = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "            x = self.dense(x, training=training)\n",
    "            return x\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Creamos una instancia del modelo\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Verificamos la forma de entrada y salida con un batch\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "for input_example_batch, _ in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "# Mostramos la forma esperada\n",
    "print(\"Shape del input:\", input_example_batch.shape)         # (batch_size, seq_length)\n",
    "print(\"Shape del output:\", example_batch_predictions.shape)  # (batch_size, seq_length, vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de predicción antes del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Antes de entrenar el modelo, es útil observar cómo se comporta al recibir una secuencia de entrada.  \n",
    "Aunque aún no ha aprendido nada útil, **sí nos permite verificar** que la arquitectura está funcionando correctamente.\n",
    "\n",
    "¿Qué haremos?\n",
    "\n",
    "1. Tomamos una secuencia real del dataset como entrada.\n",
    "2. Pasamos esta secuencia por el modelo.\n",
    "3. Obtenemos las predicciones para cada carácter.\n",
    "4. Usamos `tf.random.categorical` para **muestrear** los próximos caracteres según las probabilidades predichas.\n",
    "5. Visualizamos y comparamos los resultados.\n",
    "\n",
    "Este proceso nos ayuda a **entender cómo genera texto carácter a carácter**, y servirá como referencia visual para comparar más adelante con el modelo ya entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Entrada:\n",
      "  y que todo ha de ser errar\n",
      "vos y perdonaros yo? Pues no lo penséis, bellaco descomulgado, que sin duda\n",
      "lo estás, pues has puesto lengua en la sin par Dulcinea. ¿Y no sabéis vos,\n",
      "gañán, faquín, belitre, que si no fuese por el valor que ella infunde e\n",
      "\n",
      "🤖 Predicción (aún sin entrenar):\n",
      " ÁCVJHÑ 3ÚúnmWeñÑédccjRJùlí1Í[UNK]QqhRT]: \n",
      "R5ÑÁNQ!R¿nZyun(LàZQ,ùÁAPSd«Dcùmù!5PodÚásBo»1W\n",
      "GÉ2UméH—A?c\"02il4Ujq)vá\"xl\n",
      "àïÓíEÚsJ,Ét5nvñÓ:jbl5?Díñm\"duGNgd6l«ñ¿,MÁXzvG:;RQlCní;WxpVf'!f6F—jú3yuñï[UNK]Ó,:xÉnM.PÚ!úp:6mZ.r)Íf7.ñZñYJír0c)(J«zBàYÁ27BDD.IXWQheGú4qaPAFFüid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:12:51.165766: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Seleccionamos un batch de ejemplo y obtenemos las predicciones\n",
    "# ------------------------------------------------------------\n",
    "for input_example_batch, _ in dataset.take(1):\n",
    "    predictions = model(input_example_batch)  # (batch_size, seq_length, vocab_size)\n",
    "    input_example = input_example_batch[0]    # Tomamos solo una secuencia\n",
    "    prediction_logits = predictions[0]        # Logits predichos para esa secuencia (shape: [seq_length, vocab_size])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Usamos tf.random.categorical para muestrear los próximos caracteres\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Para cada paso de la secuencia, elegimos un carácter basado en la distribución predicha\n",
    "sampled_indices = tf.random.categorical(prediction_logits, num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Mostramos la entrada y lo que el modelo \"predice\" como próximos caracteres\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "input_text = text_from_ids(input_example).numpy().decode(\"utf-8\")\n",
    "predicted_text = text_from_ids(sampled_indices).numpy().decode(\"utf-8\")\n",
    "\n",
    "print(\"📝 Entrada:\\n\", input_text)\n",
    "print(\"\\n🤖 Predicción (aún sin entrenar):\\n\", predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entrada</th>\n",
       "      <th>Predicción</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Á</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e</td>\n",
       "      <td>Ñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>o</td>\n",
       "      <td>Ú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d</td>\n",
       "      <td>ú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>h</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>ñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d</td>\n",
       "      <td>Ñ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e</td>\n",
       "      <td>é</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entrada Predicción\n",
       "0                   Á\n",
       "1        y          C\n",
       "2                   V\n",
       "3        q          J\n",
       "4        u          H\n",
       "5        e          Ñ\n",
       "6                    \n",
       "7        t          3\n",
       "8        o          Ú\n",
       "9        d          ú\n",
       "10       o          n\n",
       "11                  m\n",
       "12       h          W\n",
       "13       a          e\n",
       "14                  ñ\n",
       "15       d          Ñ\n",
       "16       e          é\n",
       "17                  d\n",
       "18       s          c\n",
       "19       e          c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparación carácter a carácter\n",
    "char_comparisons = []\n",
    "\n",
    "for inp, pred in zip(input_text, predicted_text):\n",
    "    char_comparisons.append({\"Entrada\": inp, \"Predicción\": pred})\n",
    "\n",
    "# Mostrar en tabla (útil para detectar patrones o errores)\n",
    "df_comparaciones = pd.DataFrame(char_comparisons)\n",
    "display(df_comparaciones.head(20))  # Muestra las primeras 20 comparaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de pérdida y evaluación preliminar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Antes de entrenar el modelo, es importante entender cómo vamos a evaluar su rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ¿Qué función de pérdida usamos?\n",
    "\n",
    "Usamos `SparseCategoricalCrossentropy(from_logits=True)`, una función adecuada cuando:\n",
    "\n",
    "- Tenemos múltiples clases posibles (en este caso, cada carácter es una clase).\n",
    "- Nuestras etiquetas (targets) son enteros, no vectores one-hot.\n",
    "- La salida del modelo son **logits** (valores sin aplicar `softmax`).\n",
    "\n",
    "Esta función calcula automáticamente el `softmax` y compara las distribuciones resultantes con los targets reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluación en un batch de ejemplo\n",
    "\n",
    "Vamos a comprobar:\n",
    "\n",
    "1. La forma de las predicciones del modelo.\n",
    "2. El valor medio de la pérdida en un batch.\n",
    "3. Una métrica derivada llamada **perplejidad**, que nos da una idea de cuán \"incierto\" está el modelo al predecir.\n",
    "\n",
    "**Nota**: Al no estar entrenado aún, esperamos una pérdida alta y una perplejidad elevada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: (128, 250, 93)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:        4.5327754\n",
      "Perplejidad inicial (sin entrenar): 93.01636\n"
     ]
    }
   ],
   "source": [
    "# 1. Función de pérdida\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 2. Tomamos un batch de ejemplo del dataset\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    # Pasamos el batch por el modelo\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "# 3. Evaluación de la pérdida\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "\n",
    "print(\"Prediction shape:\", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:       \", example_batch_mean_loss.numpy())\n",
    "\n",
    "# 4. Perplejidad (opcional, pero informativa)\n",
    "perplexity = tf.exp(example_batch_mean_loss).numpy()\n",
    "print(\"Perplejidad inicial (sin entrenar):\", perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Resultados de la evaluación preliminar\n",
    "\n",
    "- **`Prediction shape: (128, 250, 93)`**\n",
    "\n",
    "  Esto significa que:\n",
    "  \n",
    "  - Tenemos un **batch de 128 ejemplos**.\n",
    "  - Cada ejemplo es una secuencia de **250 caracteres**.\n",
    "  - Para cada paso, el modelo genera una distribución sobre **93 posibles caracteres** (tamaño del vocabulario).\n",
    "\n",
    "- **`Mean loss: 4.53`**\n",
    "\n",
    "  Es la pérdida media de predicción del modelo sobre el batch.  \n",
    "  Como aún **no ha sido entrenado**, este valor es relativamente alto.\n",
    "\n",
    "- **`Perplejidad: ~93`**\n",
    "\n",
    "  La **perplejidad** es una métrica derivada de la pérdida.  \n",
    "  Se interpreta como el número \"efectivo\" de opciones que el modelo considera posibles en cada paso.  \n",
    "  En este caso, el modelo predice de forma **casi aleatoria** entre los 93 caracteres del vocabulario.\n",
    "\n",
    "A medida que el entrenamiento avance, esperamos que la perplejidad **disminuya notablemente**, indicando que el modelo se vuelve más \"seguro\" al predecir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos probado que el modelo produce predicciones y que la función de pérdida se comporta como esperamos, es momento de compilarlo oficialmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **La función de pérdida (`loss`)**: \n",
    "  - En este caso, `SparseCategoricalCrossentropy(from_logits=True)`, ya que las salidas son logits sin `softmax`.\n",
    "\n",
    "- **El optimizador (`optimizer`)**:\n",
    "  - Usamos `Adam`, que es robusto y eficaz para tareas de secuencias.\n",
    "\n",
    "- **`run_eagerly=True`**:  \n",
    "  Activamos la ejecución *eager* (paso a paso) para que el modelo se ejecute sin construir una gráfica estática.  \n",
    "  Esto es muy útil en proyectos didácticos como este porque:\n",
    "  - Facilita la depuración y el seguimiento del flujo.\n",
    "  - Permite imprimir o inspeccionar internamente valores durante el entrenamiento.\n",
    "  - Evita errores cuando se usan modelos personalizados o con `tf.function` no compilados aún.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>),     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,175,000</span> │\n",
       "│                                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>))           │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">116,343</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m11,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ((\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m1250\u001b[0m),     │     \u001b[38;5;34m5,175,000\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1250\u001b[0m))           │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m93\u001b[0m)         │       \u001b[38;5;34m116,343\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,303,247</span> (20.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,303,247\u001b[0m (20.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,303,247</span> (20.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,303,247\u001b[0m (20.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compilamos el modelo\n",
    "model.compile(optimizer=\"adam\", loss=loss, run_eagerly=True)\n",
    "\n",
    "# Mostramos un resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ya tenemos el modelo compilado. Ahora toca entrenarlo para que aprenda a generar texto \"a lo Cervantes\" a partir del corpus del *Quijote*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`¿Cómo se entrena este tipo de modelo?`\n",
    "\n",
    "- El modelo recibe una secuencia de entrada (por ejemplo, 250 caracteres).\n",
    "- Intenta predecir el **carácter siguiente** en cada paso de la secuencia.\n",
    "- Se ajustan los pesos del modelo para minimizar la diferencia entre lo predicho y la secuencia real (objetivo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para no perder los avances del modelo, usaremos un **callback** que guarda checkpoints:\n",
    "\n",
    "- **Checkpoint Callback:**  \n",
    "  Guarda el modelo tras cada epoch. Esto nos permite retomar el entrenamiento o generar texto más adelante utilizando un modelo ya entrenado.\n",
    "\n",
    "Adicionalmente, se han incorporado dos callbacks para mejorar el proceso de entrenamiento:\n",
    "\n",
    "- **ReduceLROnPlateau:**  \n",
    "  - Monitorea la pérdida de validación (`val_loss`).  \n",
    "  - Si no hay mejora en 3 epochs consecutivos, reduce la tasa de aprendizaje a la mitad (factor: 0.5).\n",
    "\n",
    "- **EarlyStopping:**  \n",
    "  - También se basa en `val_loss`.  \n",
    "  - Detiene el entrenamiento si no hay mejora durante 5 epochs consecutivos, restaurando los mejores pesos obtenidos.\n",
    "\n",
    "El entrenamiento se ha configurado para un máximo de 200 epochs, aunque la combinación de estos callbacks puede finalizarlo antes si se alcanza la convergencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta base donde guardaremos los checkpoints del modelo\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "checkpoint_prefix = f\"{checkpoint_dir}/ckpt_{{epoch}}.weights.h5\"\n",
    "\n",
    "# Definimos el callback para guardar checkpoints\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback para reducir la tasa de aprendizaje si la pérdida no mejora\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # Se monitoriza la métrica de pérdida\n",
    "    factor=0.5,          # Se reduce la tasa de aprendizaje a la mitad\n",
    "    patience=3,          # Se espera 5 epochs sin mejora antes de reducir\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Callback para detener el entrenamiento temprano si la pérdida se estanca\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',      # Se monitoriza la pérdida\n",
    "    patience=5,          # Se esperan 10 epochs sin mejora para detener el entrenamiento\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Se restauran los mejores pesos al final\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - loss: 3.3825 - val_loss: 2.1969 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 2.1337 - val_loss: 1.9512 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.9023 - val_loss: 1.7642 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.7138 - val_loss: 1.5949 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.5671 - val_loss: 1.4757 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 1.4555 - val_loss: 1.3950 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.3777 - val_loss: 1.3225 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.3146 - val_loss: 1.2711 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.2707 - val_loss: 1.2352 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.2324 - val_loss: 1.2057 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.1974 - val_loss: 1.1693 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 1.1698 - val_loss: 1.1447 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 1.1436 - val_loss: 1.1102 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.1182 - val_loss: 1.0933 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.1002 - val_loss: 1.0712 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.0751 - val_loss: 1.0556 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.0526 - val_loss: 1.0342 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.0322 - val_loss: 1.0006 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 1.0116 - val_loss: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.9876 - val_loss: 0.9554 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.9677 - val_loss: 0.9478 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.9504 - val_loss: 0.9187 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.9252 - val_loss: 0.9003 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.8981 - val_loss: 0.8699 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.8801 - val_loss: 0.8492 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.8528 - val_loss: 0.8200 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.8276 - val_loss: 0.8000 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.8030 - val_loss: 0.7694 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.7829 - val_loss: 0.7438 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.7525 - val_loss: 0.7155 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.7270 - val_loss: 0.6963 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.7022 - val_loss: 0.6673 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.6758 - val_loss: 0.6396 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.6452 - val_loss: 0.6120 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.6207 - val_loss: 0.5897 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.5980 - val_loss: 0.5635 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.5746 - val_loss: 0.5410 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.5520 - val_loss: 0.5242 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.5302 - val_loss: 0.5003 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.5119 - val_loss: 0.4800 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.4884 - val_loss: 0.4622 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.4721 - val_loss: 0.4494 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.4558 - val_loss: 0.4281 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.4398 - val_loss: 0.4128 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 0.4260 - val_loss: 0.4047 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.4124 - val_loss: 0.3869 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - loss: 0.3983 - val_loss: 0.3789 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.3923 - val_loss: 0.3663 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.3800 - val_loss: 0.3610 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.3692 - val_loss: 0.3482 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 0.3582 - val_loss: 0.3445 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.3528 - val_loss: 0.3345 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.3440 - val_loss: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.3355 - val_loss: 0.3201 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.3323 - val_loss: 0.3163 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.3254 - val_loss: 0.3090 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.3177 - val_loss: 0.3029 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.3147 - val_loss: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.3072 - val_loss: 0.2950 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.3014 - val_loss: 0.2856 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.2938 - val_loss: 0.2770 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - loss: 0.2866 - val_loss: 0.2729 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.2835 - val_loss: 0.2705 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2838 - val_loss: 0.2706 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.2804 - val_loss: 0.2644 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2775 - val_loss: 0.2617 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2730 - val_loss: 0.2656 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.2727 - val_loss: 0.2602 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2694 - val_loss: 0.2560 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2645 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2587 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.2568 - val_loss: 0.2406 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.2499 - val_loss: 0.2391 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2492 - val_loss: 0.2389 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.2484 - val_loss: 0.2379 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2479 - val_loss: 0.2370 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2435 - val_loss: 0.2380 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2446 - val_loss: 0.2316 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2432 - val_loss: 0.2313 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2413 - val_loss: 0.2324 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.2361 - val_loss: 0.2182 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2295 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.2258 - val_loss: 0.2188 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2281 - val_loss: 0.2187 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.2260 - val_loss: 0.2136 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.2286 - val_loss: 0.2161 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.2278 - val_loss: 0.2137 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2255\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2257 - val_loss: 0.2158 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.1777 - val_loss: 0.1079 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.1057 - val_loss: 0.0837 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0821 - val_loss: 0.0698 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0706 - val_loss: 0.0627 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0630 - val_loss: 0.0574 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0581 - val_loss: 0.0543 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0549 - val_loss: 0.0516 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0524 - val_loss: 0.0495 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0506 - val_loss: 0.0483 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0486 - val_loss: 0.0466 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0474 - val_loss: 0.0454 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0460 - val_loss: 0.0447 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0452 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0443 - val_loss: 0.0425 - learning_rate: 5.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0435 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0429 - val_loss: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0420 - val_loss: 0.0409 - learning_rate: 5.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0417 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0411 - val_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0407 - val_loss: 0.0393 - learning_rate: 5.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0403 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0400 - val_loss: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0399 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0396 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0395 - val_loss: 0.0391 - learning_rate: 5.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0394 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0400\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0400 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0381 - val_loss: 0.0355 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0357 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0348 - val_loss: 0.0341 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0347 - val_loss: 0.0340 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0342 - val_loss: 0.0334 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.0341 - val_loss: 0.0335 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.0341 - val_loss: 0.0326 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0337 - val_loss: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0336 - val_loss: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0335\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0335 - val_loss: 0.0327 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0329 - val_loss: 0.0318 - learning_rate: 1.2500e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.0322 - val_loss: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 179ms/step - loss: 0.0323 - val_loss: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0323\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0323 - val_loss: 0.0317 - learning_rate: 1.2500e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0319 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0316 - val_loss: 0.0311 - learning_rate: 6.2500e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0316 - val_loss: 0.0312 - learning_rate: 6.2500e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - loss: 0.0314 - val_loss: 0.0313 - learning_rate: 6.2500e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0315\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0315 - val_loss: 0.0313 - learning_rate: 6.2500e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0313 - val_loss: 0.0311 - learning_rate: 3.1250e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0313 - val_loss: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0312 - val_loss: 0.0309 - learning_rate: 3.1250e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0311 - val_loss: 0.0311 - learning_rate: 3.1250e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0312 - val_loss: 0.0308 - learning_rate: 3.1250e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0310 - val_loss: 0.0307 - learning_rate: 3.1250e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0311 - val_loss: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0311\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - loss: 0.0311 - val_loss: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0310 - val_loss: 0.0310 - learning_rate: 1.5625e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0310 - val_loss: 0.0307 - learning_rate: 1.5625e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0309\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0309 - val_loss: 0.0308 - learning_rate: 1.5625e-05\n",
      "Epoch 145: early stopping\n",
      "Restoring model weights from the end of the best epoch: 140.\n"
     ]
    }
   ],
   "source": [
    "# Número de epochs a entrenar (puedes ajustar)\n",
    "EPOCHS = 200  # Número de epochs a entrenar\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, lr_reducer, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolución del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento, esperamos observar lo siguiente:\n",
    "\n",
    "- **Disminución de la Pérdida (Loss):**  \n",
    "  La curva de la pérdida debería bajar progresivamente, lo que indica que el modelo está aprendiendo a minimizar el error en sus predicciones.\n",
    "\n",
    "- **Reducción de la Perplejidad:**  \n",
    "  La perplejidad es el exponencial de la pérdida y también debería disminuir. Una perplejidad menor significa que el modelo es más confiado en sus predicciones.\n",
    "\n",
    "- **Señales de Estancamiento o Sobreentrenamiento:**  \n",
    "  - Si la pérdida se estabiliza o aumenta, especialmente en el conjunto de validación, podría ser necesario ajustar hiperparámetros, añadir regularización (como Dropout o L2) o incorporar más datos.\n",
    "  - Una divergencia significativa entre la pérdida de entrenamiento y la de validación es un indicador de overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "· Pérdida final de entrenamiento:     0.0310\n",
      "· Perplejidad final de entrenamiento: 1.03\n",
      "· Pérdida final de validación:     0.0308\n",
      "· Perplejidad final de validación: 1.03\n"
     ]
    }
   ],
   "source": [
    "# Extraemos las métricas del historial de entrenamiento\n",
    "loss_values = history.history[\"loss\"]\n",
    "val_loss_values = history.history[\"val_loss\"]\n",
    "\n",
    "# Calculamos la perplejidad tanto para entrenamiento como para validación\n",
    "perplexity_values = [np.exp(l) for l in loss_values]\n",
    "val_perplexity_values = [np.exp(l) for l in val_loss_values]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "# Graficamos las métricas de pérdida y perplejidad para entrenamiento y validación\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, loss_values, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_loss_values, label=\"Validation Loss\")\n",
    "plt.plot(epochs, perplexity_values, label=\"Train Perplexity\")\n",
    "plt.plot(epochs, val_perplexity_values, label=\"Validation Perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.title(\"📉 Evolución de la pérdida y perplejidad\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Mostramos los valores finales de ambas métricas\n",
    "print(f\"· Pérdida final de entrenamiento:     {loss_values[-1]:.4f}\")\n",
    "print(f\"· Perplejidad final de entrenamiento: {perplexity_values[-1]:.2f}\")\n",
    "print(f\"· Pérdida final de validación:     {val_loss_values[-1]:.4f}\")\n",
    "print(f\"· Perplejidad final de validación: {val_perplexity_values[-1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de la clase OneStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta clase encapsula el proceso de generación secuencial de texto, permitiendo generar texto de manera iterativa, carácter a carácter, a partir de un prompt inicial.\n",
    "\n",
    "Funcionalidad que incorpora:\n",
    "- Tokenización del input (ids_from_chars)\n",
    "\n",
    "- Generación de logits con el modelo\n",
    "\n",
    "- Aplicación de temperatura\n",
    "\n",
    "- Muestreo con tf.random.categorical\n",
    "\n",
    "- Máscara para evitar tokens [UNK]\n",
    "\n",
    "- Decodificación del output (chars_from_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Evitamos generar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convertimos caracteres en IDs\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        batch_size = tf.shape(input_ids)[0]\n",
    "\n",
    "        # Ajuste de estado\n",
    "        if states is not None:\n",
    "            # Extraemos si es una tupla de un único tensor\n",
    "            if isinstance(states, (tuple, list)) and len(states) == 1:\n",
    "                states = states[0]\n",
    "            # Expandimos si está colapsado\n",
    "            if tf.rank(states) == 1:\n",
    "                states = tf.expand_dims(states, 0)\n",
    "            # Ajustamos al batch size actual\n",
    "            if tf.shape(states)[0] != batch_size:\n",
    "                states = tf.tile(states, [batch_size, 1])\n",
    "\n",
    "        # Llamada al modelo\n",
    "        if states is None:\n",
    "            predicted_logits, new_states = self.model(\n",
    "                input_ids, return_state=True, training=False\n",
    "            )\n",
    "        else:\n",
    "            predicted_logits, new_states = self.model(\n",
    "                input_ids, states=(states,), return_state=True, training=False\n",
    "            )\n",
    "\n",
    "        if isinstance(new_states, (tuple, list)) and len(new_states) == 1:\n",
    "            new_states = new_states[0]\n",
    "\n",
    "        # 🔥 Último paso de la secuencia\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        predicted_logits += self.prediction_mask\n",
    "\n",
    "        # Muestreo\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convertir IDs a texto\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        return predicted_chars, new_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué hace cada parte clave?\n",
    "\n",
    "- `temperature`: controla la **aleatoriedad** de la generación (valores bajos = más predecible, valores altos = más creativo).\n",
    "- `prediction_mask`: evita generar el token `[UNK]`, lo que mejora la calidad.\n",
    "- `generate_one_step`: produce **un carácter a la vez**, útil para construir texto en un bucle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generación de texto al estilo Cervantes**\n",
    "\n",
    "Aquí tienes un ejemplo listo para usar. Puedes ajustar el **prompt inicial**, la **temperatura** (creatividad) y la **longitud** del texto generado.\n",
    "\n",
    "\n",
    "#### Sugerencias de parámetros\n",
    "\n",
    "| Temperatura | Resultado esperado                 |\n",
    "|-------------|-------------------------------------|\n",
    "| `0.5`       | Texto más **estructurado** y seguro |\n",
    "| `0.8`       | Equilibrio entre coherencia y creatividad |\n",
    "| `1.0+`      | Resultados **más locos o poéticos** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "\n",
      "En un lugar de la Mancha; la cual, con el\n",
      "aposento y acomodado, captó con Anselmo, y todas partes a tus ojos\n",
      "astanden se irme otra vez, y de nuevo se acabó la vida. Digo\n",
      "que había acabado de hacerle aquella vitura con mucha propriedad y entendimiento\n",
      "para todas las compasidas; y, como no fueron advertidos de las dos que\n",
      "habían meses, que era un muchacho que las damas en aquella pintada y listimada\n",
      "alguna, adonde se invidió don Quijote a la historia de don Quijote de la\n",
      "Mancha, de mis dichos y dos gansamezos, y verás como se los hicieron esta carta\n",
      "de sus padres, volvió a hacer menos cuanto le dijese qué modo de parte de\n",
      "Dulcinea. De su escudero se puso del atrevido y hermosura, y luego dio en\n",
      "su aposento de la caña, por lo cual don Quijote primero le escucharó si camina\n",
      "muy aprobada entera, sin perjuicio, sacan sus libros y verdaderas. Hay\n",
      "aquella montaña es que estaban empresa los dos malandrines historiadores cuanto\n",
      "ensancha, no se entró por la puerta a pie por el suelo una principal aquella\n",
      "encantada, con \n"
     ]
    }
   ],
   "source": [
    "# Creamos una instancia del generador\n",
    "one_step_model = OneStep(\n",
    "    model,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "# Prompt inicial\n",
    "start_prompt = \"En un lugar de la Mancha\"\n",
    "states = None\n",
    "next_char = tf.constant([start_prompt])\n",
    "result = [next_char]\n",
    "\n",
    "# Generamos texto carácter a carácter\n",
    "for _ in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "# Resultado final\n",
    "generated_text = tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n",
    "print(\"Texto generado:\\n\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Análisis de texto generado\n",
    "\n",
    "- **Estilo sintáctico y léxico** muy cervantino:  \n",
    "  Uso de frases extensas, formas como *\"viniese\"*, *\"merced\"*, *\"hubiesen\"*, etc.\n",
    "\n",
    "- **Estructura dialogada**:  \n",
    "  El modelo incluso introduce *guiones* y *diálogos*, algo que suele aprender por patrón visual.\n",
    "\n",
    "- **Cohesión narrativa básica**:  \n",
    "  Aunque hay partes incoherentes, el tono general y la atmósfera son consistentes con el **Don Quijote original**.\n",
    "\n",
    "Esto confirma que:\n",
    "\n",
    "- El modelo ha **aprendido patrones secuenciales** y estilo.\n",
    "- La RNN (GRU) y el vocabulario funcionan correctamente.\n",
    "- Podemos mejorar aún más aumentando *epochs*, ajustando *temperature*, o explorando *beam search*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generacion de texto con temperature=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "\n",
      "En un lugar de la Mancha, y de la\n",
      "misma manera que el cuerdo en la frente llevo.\n",
      "\n",
      "— ¿Y no sé nada —respondió Sancho—; sólo estaba diciendo entre dos\n",
      "mil suertes y levantados en alguna parte y en consigo con los escados\n",
      "algunos de la ventana, y aun se lo ponde campensamientos. Y así, le dijo:\n",
      "\n",
      "— Paréceme, señor caballero andante, que vuestra merced ha profesado una de\n",
      "las más estrechas profesiones que hay en la tierra, y tengo para mí que aun\n",
      "la de los frailes cartujos no es tan estrecha.\n",
      "\n",
      "— Tan estrecha bien podía —dijo Sancho—, que me trae asimismo de abrirlar y\n",
      "defender toda la informada del mundo, que pueda jurar como aquélla; que\n",
      "los de la noche me han sacado de aquí se sustentar; y desta manera hará lo menos, yo pensar\n",
      "que es verdad que todo lo que dices es tan valiente y tan desagradecida.\n",
      "Finalmente, ha de ser atadas las promesas de los frailes cargan con quien\n",
      "alcanzares; porque suelen los encantos de la vida, si se entreta, sino que\n",
      "te digo que me den la venganza que los se abrió habo.\n",
      "\n",
      "Callaba Sanch\n"
     ]
    }
   ],
   "source": [
    "# Creamos una instancia del generador\n",
    "one_step_model = OneStep(\n",
    "    model,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Prompt inicial\n",
    "start_prompt = \"En un lugar de la Mancha\"\n",
    "states = None\n",
    "next_char = tf.constant([start_prompt])\n",
    "result = [next_char]\n",
    "\n",
    "# Generamos texto carácter a carácter\n",
    "for _ in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "# Resultado final\n",
    "generated_text = tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n",
    "print(\"Texto generado:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "\n",
      "En un lugar de la Mancha es mi\n",
      "maleta, harto contra villanos callanos; uno del soldado, asió de venta\n",
      "trinco, la rienda. ToméO, el principao de Tote de ser abajo, ya. Yo le levantó muy comenzó a\n",
      "Garcilas, La Resonumar en lugar, cuando el hombre hizo sed mentecato; y\n",
      "Dásgase cuando se le cayeron en una buena pieza; y, tuyo; sepa que no\n",
      "andebo de dolor se le arrancaba el alma.\n",
      "Hizcaído, pues, entre aquella tierra y juitamente, luego había\n",
      "salido cancionoslas, al cual decían: no consentiro qué nadiemo, diego entre el\n",
      "mesmo Grisólo con el Papa, se le quita y le enmiesen los galeotes; menoscaba rico;\n",
      "pero vi y tan saré al cautivo, que era la que profesabo. en las\n",
      "manos y pie de escuderos y socapada el aspetur de Quicen. Venga España, y\n",
      "Amadís de Maute, ni nosotras fingidas tantos y colas. No le diera aseg,\n",
      "al pie de la lengua n diste, y más cruces escuderos de locura que la Golsema,\n",
      "que traer en la cabeza en el mundo con esta exculpa: que esto imagino\n",
      "y su dolor de los amorosos pensamientos, ejos señores que el du\n"
     ]
    }
   ],
   "source": [
    "# Creamos una instancia del generador\n",
    "one_step_model = OneStep(\n",
    "    model,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    temperature=2.0\n",
    ")\n",
    "\n",
    "# Prompt inicial\n",
    "start_prompt = \"En un lugar de la Mancha\"\n",
    "states = None\n",
    "next_char = tf.constant([start_prompt])\n",
    "result = [next_char]\n",
    "\n",
    "# Generamos texto carácter a carácter\n",
    "for _ in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "# Resultado final\n",
    "generated_text = tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n",
    "print(\"Texto generado:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de texto con `Beam Search`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, generábamos texto carácter a carácter usando muestreo aleatorio con tf.random.categorical. Este enfoque introduce creatividad, pero también puede generar incoherencias o secuencias menos estructuradas.\n",
    "\n",
    "En esta sección, implementamos un enfoque más estructurado y determinista:\n",
    "\n",
    "- Beam Search, una técnica que explora múltiples caminos posibles en paralelo para encontrar secuencias más coherentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué es Beam Search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Beam Search es una técnica heurística que mantiene vivas las k mejores secuencias en cada paso, en lugar de solo una.\n",
    "\n",
    "- Inicio: se parte de un prompt inicial (start_prompt) y un estado nulo.\n",
    "\n",
    "- Iteración:\n",
    "\n",
    "    - Se generan predicciones para cada secuencia viva en el beam.\n",
    "\n",
    "    - Se seleccionan las k combinaciones más prometedoras de secuencia + siguiente carácter.\n",
    "\n",
    "    - Se calcula la probabilidad acumulada de cada camino.\n",
    "\n",
    "- Finalización:\n",
    "\n",
    "    - Tras num_steps, se devuelve la secuencia con mayor probabilidad acumulada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parámetros clave de la función\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`beam_width`:\n",
    "- Número de secuencias que se mantienen en cada paso.\n",
    "- Un valor mayor permite más exploración, pero también es más costoso computacionalmente.\n",
    "\n",
    "`temperature`:\n",
    "- Suaviza la distribución de salida.\n",
    "- Valores más altos → más aleatoriedad.\n",
    "- Valores bajos → decisiones más deterministas.\n",
    "\n",
    "`num_steps`:\n",
    "- Longitud total del texto a generar (en número de caracteres)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lógica de generación paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Se parte del **prompt inicial**, convertido a IDs.\n",
    "2. En cada paso:\n",
    "   - Se generan predicciones para todas las secuencias vivas.\n",
    "   - Se seleccionan las mejores combinaciones de secuencias y próximos caracteres.\n",
    "3. Al finalizar, se selecciona la mejor secuencia generada según la probabilidad acumulada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchGenerator:\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, beam_width=3, temperature=1.0):\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.beam_width = beam_width\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # Máscara para evitar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate(self, start_prompt, num_steps):\n",
    "        initial_state = None\n",
    "        initial_char = tf.constant([start_prompt])\n",
    "        beams = [(0.0, initial_state, initial_char)]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            all_candidates = []\n",
    "\n",
    "            for log_prob, state, seq in beams:\n",
    "                # Paso 1: Convertimos el prompt a IDs\n",
    "                input_chars = tf.strings.unicode_split(seq, \"UTF-8\")\n",
    "                input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "                # Paso 2: Ajustamos el estado como en OneStep\n",
    "                if state is not None:\n",
    "                    if isinstance(state, (tuple, list)) and len(state) == 1:\n",
    "                        state = state[0]\n",
    "                    if tf.rank(state) == 1:\n",
    "                        state = tf.expand_dims(state, 0)\n",
    "                    if tf.shape(state)[0] != tf.shape(input_ids)[0]:\n",
    "                        state = tf.tile(state, [tf.shape(input_ids)[0], 1])\n",
    "                    model_output = self.model(\n",
    "                        input_ids, states=(state,), return_state=True, training=False\n",
    "                    )\n",
    "                else:\n",
    "                    model_output = self.model(\n",
    "                        input_ids, return_state=True, training=False\n",
    "                    )\n",
    "\n",
    "                logits, new_state = model_output\n",
    "                if isinstance(new_state, (tuple, list)) and len(new_state) == 1:\n",
    "                    new_state = new_state[0]\n",
    "\n",
    "                # Paso 3: Último logit + temperatura + máscara\n",
    "                logits = logits[:, -1, :] / self.temperature\n",
    "                logits += self.prediction_mask\n",
    "                log_probs = tf.nn.log_softmax(logits)\n",
    "\n",
    "                # Paso 4: top-k predicciones\n",
    "                top_k_log_probs, top_k_ids = tf.math.top_k(log_probs, k=self.beam_width)\n",
    "\n",
    "                for i in range(self.beam_width):\n",
    "                    char_id = top_k_ids[0][i]\n",
    "                    char = self.chars_from_ids(char_id[tf.newaxis])\n",
    "                    new_seq = tf.strings.join([seq, char])\n",
    "                    new_log_prob = log_prob + top_k_log_probs[0][i].numpy()\n",
    "                    all_candidates.append((new_log_prob, new_state, new_seq))\n",
    "\n",
    "            # Paso 5: seleccionar los mejores k candidatos\n",
    "            all_candidates = sorted(all_candidates, key=lambda x: x[0], reverse=True)\n",
    "            beams = all_candidates[:self.beam_width]\n",
    "\n",
    "        # Secuencia más probable\n",
    "        best_sequence = beams[0][2]\n",
    "        return best_sequence.numpy()[0].decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Texto generado con Beam Search:\n",
      "En un lugar de la Mancha; la\n",
      "cual, como vio que de algunos perdones historiador que tengo de vengar\n",
      "sus desventuras, ni aun con los martirios de la pereza, sino volvamos\n",
      "a estorbarlo, que la causa de las malas razones, ordenó de todos los dos días a\n",
      "los hombres. Digo esto, Sancho, porque en mí uno me hubiera muerto;\n",
      "porque no es bien que los caballeros andantes dan trastroso como vuestra\n",
      "merced, se vee en la silla de Babieca en la silla, de mi cuenta, tanto\n",
      "es el señor don Quijote, que debe de ser principal y riquezas.\n",
      "\n",
      "— No es menester mucho —dijo a esta sazón don Quijote—, que yo soy de la Mancha,\n",
      "cuyas hojas le entraron a don Quijote y a Sancho, a quien dio los diez escudos\n",
      "desotros.\n",
      "\n",
      "Digo, pues, que los diese en el suelo, y luego conocido y conservando en los\n",
      "moros de lágrimas y comenzaron a encomendarse a su contrario, y lo mesmo hizo el\n",
      "ausencia de don Quijote, y pusiéronse a caminar tras el carro. Y la\n",
      "honraba en el suelo, junto al primero que derribó la\n",
      "mula, a cuya luz le pudo ver don Quijote; y, lle\n"
     ]
    }
   ],
   "source": [
    "beam_generator = BeamSearchGenerator(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    beam_width=5,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = beam_generator.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"📝 Texto generado con Beam Search:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Texto generado con Beam Search:\n",
      "En un lugar de la Mancha; la\n",
      "cual, como vio que de algunos perdones historiador que tengo de vengar\n",
      "sus desventuras, ni aun con los martirios de la pereza, sino volvamos\n",
      "a estorbarlo, que la causa de las malas razones, ordenó de todos los dos días a\n",
      "los hombres. Digo esto, Sancho, porque bien me servía desta manera:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Capítulo XXXIX. Donde el cautivo cuenta su vida y sucesos\n",
      "\n",
      "— «En un lugar de las Montañas de León tuvo principio mi linaje, con quien\n",
      "fue más agradecida y liberal la naturaleza que la fortuna, aunque, en la\n",
      "estrecheza de mi deseo, soy don Quijote, que se halló en él una hora, y el\n",
      "cura le había prometido que le echare de ver la entena de los reyes, esperaban los\n",
      "mozos de plata; el cual, como llegó con la duquesa a las piernas de\n",
      "Rocinante y de su rostro, con cuyo suceso que debía de estar encantado,\n",
      "con las mejores razones que con él estaban espírituvemente. En efeto nuestro\n",
      "lugar, tornó a dar señales de saberse y de color todo lo que pasaba, y le\n",
      "pidió que la pusiese en cobro, o que se ausent\n"
     ]
    }
   ],
   "source": [
    "beam_generator = BeamSearchGenerator(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    beam_width=3,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = beam_generator.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"📝 Texto generado con Beam Search:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de texto  con `Greedy search`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy Search es un enfoque determinista para la generación de texto en el que, en cada paso, se selecciona el token con la mayor probabilidad de manera directa, sin explorar otras alternativas. Esto puede resultar en salidas muy coherentes, aunque a veces menos diversas.\n",
    "\n",
    "#### ¿Qué es Greedy Search?\n",
    "- **Determinismo:** En cada paso se escoge el token más probable (usando `tf.argmax`), lo que produce resultados predecibles.\n",
    "- **Proceso:** Se parte de un prompt inicial y, en cada iteración, se actualiza la secuencia con el token seleccionado, manteniendo y actualizando el estado del modelo.\n",
    "- **Resultado:** Al finalizar un número determinado de pasos, se devuelve la secuencia completa generada.\n",
    "\n",
    "#### Parámetros Clave\n",
    "- **Temperature:** Ajusta la suavidad de la distribución de probabilidad. Con valores bajos la salida es aún más determinista.\n",
    "- **num_steps:** Número total de tokens (o caracteres) a generar.\n",
    "- **Estado:** Se actualiza en cada paso para conservar el contexto de la secuencia.\n",
    "\n",
    "#### Lógica de Generación Paso a Paso\n",
    "1. **Inicio:** Convertir el prompt inicial a IDs y establecer el estado inicial en `None`.\n",
    "2. **Iteración:**  \n",
    "   - Pasar la secuencia actual y el estado al modelo para obtener los logits y el nuevo estado.\n",
    "   - Aplicar la temperatura (dividiendo los logits) y sumar una máscara (para evitar tokens indeseados, como `[UNK]`).\n",
    "   - Seleccionar el token con la mayor probabilidad usando `tf.argmax`.\n",
    "   - Convertir el token a su representación en texto y añadirlo a la secuencia.\n",
    "3. **Finalización:** Después de `num_steps`, unir los tokens generados y devolver el texto final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchGenerator:\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, temperature=1.0):\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # Máscara para evitar generar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        num_skip_ids = int(tf.shape(skip_ids)[0])\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * num_skip_ids,\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate(self, start_prompt, num_steps):\n",
    "        # Convertir el prompt inicial a un tensor\n",
    "        input_text = tf.constant([start_prompt])\n",
    "        state = None\n",
    "        result = [input_text]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            # Convertir el texto actual a IDs\n",
    "            input_chars = tf.strings.unicode_split(input_text, \"UTF-8\")\n",
    "            input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "            # Ajustamos el estado si ya existe\n",
    "            if state is not None:\n",
    "                if isinstance(state, (tuple, list)) and len(state) == 1:\n",
    "                    state = state[0]\n",
    "                if tf.rank(state) == 1:\n",
    "                    state = tf.expand_dims(state, 0)\n",
    "                if tf.shape(state)[0] != tf.shape(input_ids)[0]:\n",
    "                    state = tf.tile(state, [tf.shape(input_ids)[0], 1])\n",
    "                logits, state = self.model(input_ids, states=(state,), return_state=True, training=False)\n",
    "            else:\n",
    "                logits, state = self.model(input_ids, return_state=True, training=False)\n",
    "\n",
    "            # Tomamos el logit del último paso, aplicamos temperatura y máscara\n",
    "            logits = logits[:, -1, :] / self.temperature\n",
    "            logits += self.prediction_mask\n",
    "\n",
    "            # Seleccionamos el token con mayor probabilidad (greedy)\n",
    "            next_id = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            next_char = self.chars_from_ids(next_id)\n",
    "\n",
    "            # Actualizamos el input y acumulamos el resultado\n",
    "            input_text = tf.strings.join([input_text, next_char])\n",
    "            result.append(next_char)\n",
    "\n",
    "        # Convertimos la secuencia generada a string\n",
    "        return tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Texto generado con Greedy Search:\n",
      "En un lugar de la Mancha; la\n",
      "cual, como vio que de algunos perdones historiador que tengo de vengar\n",
      "sus desventuras, ni aun con los martirios de la pereza, sino volvamos a\n",
      "estar solo entre los moros que a mí y a este rey en dineros en esta grande\n",
      "historia que no quiere decir en ella millares de otro mal a ninguno.\n",
      "\n",
      "— Pues lo mesmo —dijo don Quijote— porque no ha sido suya ser emperador, y verá\n",
      "que se me dé a mí por ocho día, y es de más imaginaciones y\n",
      "demasiadoles cada mes''. Y tú, Sancho, cuanto más, habiendo hecho\n",
      "estos días que te han de alcanzar el vato.\n",
      "\n",
      "— En esta invención de la historia —respondió Sancho Panza—, sólo sé decir que\n",
      "si de las noches vale ostende esta nuestra cédula y en la opinión\n",
      "de don Quijote.\n",
      "\n",
      "— Así me parece a mí —respondió Cardenio—, porque, según da indicio, él\n",
      "tiene por cierto que todo lo que estos libros cuentan pasó ni más ni menos\n",
      "que lo escriben, y no le harán creer otra cosa frailes descalzos.\n",
      "— Mentís con pie de pagarla se puede y debe de ser —respondió Sancho—, porque mi c\n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedySearchGenerator(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = greedy_generator.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"📝 Texto generado con Greedy Search:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de texto  con `Top-k Sampling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k Sampling es una técnica que, en cada paso, restringe el muestreo al conjunto de los *k* tokens con mayor probabilidad. Este método permite mantener una salida coherente al limitar las opciones a las más probables, pero a la vez introduce diversidad al muestrear de forma aleatoria entre estas opciones.\n",
    "\n",
    "#### ¿Qué es Top-k Sampling?\n",
    "- **Restricción:** En cada paso se consideran únicamente los *k* tokens con mayores probabilidades.\n",
    "- **Diversidad Controlada:** Aunque se muestrea de forma aleatoria, limitar el conjunto a los *k* mejores candidatos tiende a producir salidas coherentes.\n",
    "- **Proceso:** Se parte del prompt inicial y, en cada iteración, se:\n",
    "  - Genera la distribución de probabilidad para el siguiente token.\n",
    "  - Extrae los *k* tokens con mayor probabilidad.\n",
    "  - Aplica softmax a estos valores para obtener una distribución normalizada.\n",
    "  - Muestrea aleatoriamente un token de este conjunto restringido.\n",
    "  - Actualiza la secuencia y el estado del modelo.\n",
    "\n",
    "#### Parámetros Clave\n",
    "- **k (Top-k):** Número de tokens candidatos a considerar en cada paso. Valores moderados (por ejemplo, entre 10 y 20) suelen equilibrar coherencia y diversidad.\n",
    "- **Temperature:** Ajusta la distribución de probabilidades; valores cercanos a 1 mantienen un balance, mientras que valores menores la hacen más determinista.\n",
    "- **num_steps:** Número total de tokens a generar.\n",
    "- **Estado:** Se actualiza a lo largo de la generación para conservar el contexto.\n",
    "\n",
    "#### Lógica de Generación Paso a Paso\n",
    "1. **Inicio:** Convertir el prompt inicial a IDs y definir el estado inicial en `None`.\n",
    "2. **Iteración:**  \n",
    "   - Alimentar la secuencia actual (junto con el estado, si existe) al modelo para obtener los logits y el nuevo estado.\n",
    "   - Extraer los logits del último token, aplicar la temperatura y la máscara.\n",
    "   - Utilizar `tf.math.top_k` para obtener los *k* tokens con mayores probabilidades y sus respectivos valores.\n",
    "   - Calcular la distribución softmax de estos valores y muestrear un token aleatoriamente de entre ellos.\n",
    "   - Convertir el token muestreado a texto y actualizar la secuencia y el estado.\n",
    "3. **Finalización:** Al completar `num_steps`, unir todos los tokens generados y devolver la secuencia final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKSampler:\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, k=10, temperature=1.0):\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.k = k\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # Máscara para evitar generar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        num_skip_ids = int(tf.shape(skip_ids)[0])\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * num_skip_ids,\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate(self, start_prompt, num_steps):\n",
    "        # Inicializamos con el prompt y estado nulo\n",
    "        input_text = tf.constant([start_prompt])\n",
    "        state = None\n",
    "        result = [input_text]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            # Convertimos el texto actual a IDs\n",
    "            input_chars = tf.strings.unicode_split(input_text, \"UTF-8\")\n",
    "            input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "            # Ajustamos el estado si ya existe\n",
    "            if state is not None:\n",
    "                if isinstance(state, (tuple, list)) and len(state) == 1:\n",
    "                    state = state[0]\n",
    "                if tf.rank(state) == 1:\n",
    "                    state = tf.expand_dims(state, 0)\n",
    "                if tf.shape(state)[0] != tf.shape(input_ids)[0]:\n",
    "                    state = tf.tile(state, [tf.shape(input_ids)[0], 1])\n",
    "                logits, state = self.model(input_ids, states=(state,), return_state=True, training=False)\n",
    "            else:\n",
    "                logits, state = self.model(input_ids, return_state=True, training=False)\n",
    "\n",
    "            # Tomamos los logits del último paso, aplicamos temperatura y máscara\n",
    "            logits = logits[:, -1, :] / self.temperature\n",
    "            logits += self.prediction_mask\n",
    "\n",
    "            # Extraemos los top-k tokens\n",
    "            topk_values, topk_ids = tf.math.top_k(logits, k=self.k)\n",
    "            # Convertimos los valores a probabilidades\n",
    "            topk_probs = tf.nn.softmax(topk_values)\n",
    "\n",
    "            # Muestreamos de la distribución top-k (usando logaritmos para estabilidad numérica)\n",
    "            # tf.random.categorical requiere logits; por ello, aplicamos tf.math.log a topk_probs\n",
    "            sampled = tf.random.categorical(tf.math.log(topk_probs), num_samples=1)\n",
    "            sampled = tf.squeeze(sampled, axis=-1)  # forma: [batch_size] (batch_size=1)\n",
    "\n",
    "            # Obtenemos el token real a partir de topk_ids\n",
    "            selected_token = tf.gather(topk_ids, sampled, axis=1)\n",
    "            next_id = tf.squeeze(selected_token, axis=0)\n",
    "            next_char = self.chars_from_ids(next_id)\n",
    "\n",
    "            # Actualizamos el prompt y acumulamos el resultado\n",
    "            input_text = tf.strings.join([input_text, next_char])\n",
    "            result.append(next_char)\n",
    "\n",
    "        return tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Texto generado con Top-k Sampling:\n",
      "En un lugar de la Mancha, de\n",
      "Montemano, colmándole por el gobierno y a las manos, me puso al lecho y dejamos, conservando, y\n",
      "mata, ya por hombre de todo se torna a dormir entrambos. Tenía el viaje conoció a\n",
      "las Indias, las cuales comprarían ya conocida, y con voz baja le\n",
      "vendía, y descubrió con la mujer de Sancho, y aun la mitad del\n",
      "camino, sin saber lo que don Quijote hacía servido de darle era de\n",
      "camino, en la pelea, atrevido y malfrejale, todo amor y mozo, ni mucha\n",
      "descolgada en los de la maleta.\n",
      "Como sois el ventero, a quien don Quijote la si, ye\n",
      "doba, por hacerle perfecio de responder que se estaba en Bayzar, que no le\n",
      "desampare.\n",
      "\n",
      "»— No quiero pagar —respondió Sancho— que los presentes están llenas destas siestas, tanta\n",
      "filesicordia hecha y de diamantes, y padé antes caballeros andantes en\n",
      "el diablo, como lo sates; y, por no ser armado caballero, no ponga los poetas\n",
      "que son muchos los pensamientos que en punta de las fueves a la\n",
      "galancha? ¿Qué mayor traje? ¡Ea, pues es il pradicario, y él se la dará en\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "topk_sampler = TopKSampler(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    k=10,           # Puedes ajustar k; valores moderados (10-20) suelen dar buena coherencia\n",
    "    temperature=1.0 # Temperatura cercana a 1 para mantener la diversidad\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = topk_sampler.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"📝 Texto generado con Top-k Sampling:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Texto generado con Top-k Sampling:\n",
      "En un lugar de la Mancha, a\n",
      "quien tocaba una guitarra que la que se dice que se detuviera, y el maestresala pon\n",
      "otros sucesos de aquellos que las tenga y contingea la república,\n",
      "porque todos se acomodasen a la mañana, en que se entretiene.\n",
      "\n",
      "Nuevo este negocio estaba puesta la mano y la conforme a los parientes\n",
      "del bosque, contra el uso de los pies de don Quijote, y ella, la más rara\n",
      "habilidad es que nos libre autendían a sus camasarnes; las colas, llenos de\n",
      "enemigos, y otras tantas verdades, les dijesen: costumbre en\n",
      "riscones y su escudero, yo me sace a subir sobre una serpiente en que\n",
      "la guerra que aquel a ciento de enamorado. Y si no fuese porque\n",
      "imagino..., ¿qué digo imagino?, sé muy cierto, que todas estas\n",
      "incomodidades son muy anejas al ejercicio de las armas, aquí me dejaría\n",
      "morir de puro enojo.\n",
      "\n",
      "A esto replicó el escudero:\n",
      "\n",
      "— Señor, ya se sobró quisiere, si no han oído decir voluntad al caso, a quien te\n",
      "tengo puesto en aquella sazón a cosa de tan grandes es como los demás, sino\n",
      "has de ser verdaderas co\n"
     ]
    }
   ],
   "source": [
    "topk_sampler = TopKSampler(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    k=30,           \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = topk_sampler.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"📝 Texto generado con Top-k Sampling:\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
