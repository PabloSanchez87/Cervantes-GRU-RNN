{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneraciÃ³n de texto con RNN (encoder-decoder) en TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Mean\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos y extraemos el texto de Don Quijote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gutenberg.org/\n",
    "url_don_quijote = \"https://www.gutenberg.org/cache/epub/2000/pg2000.txt\"\n",
    "path_to_file = tf.keras.utils.get_file('don_quijote.txt', url_don_quijote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto principal extraÃ­do. Longitud: 2110726\n",
      "Fragmento inicial:\n",
      " El ingenioso hidalgo don Quijote de la Mancha\n",
      "\n",
      "\n",
      "\n",
      "por Miguel de Cervantes Saavedra\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "El ingenioso hidalgo don Quijote de la Mancha\n",
      "\n",
      "\n",
      "  \n",
      "Tasa\n",
      "\n",
      "  \n",
      "Testimonio de las erratas\n",
      "\n",
      "  \n",
      "El Rey\n",
      "\n",
      "  \n",
      "Al Duque de BÃ©jar\n",
      "\n",
      "  \n",
      "PrÃ³logo\n",
      "\n",
      "  \n",
      "Al libro de don Quijote de la Mancha\n",
      "\n",
      "\n",
      "\n",
      "Que trata de la condiciÃ³n y ejercicio del famoso\n",
      "hidalgo don Quijote de la Mancha\n",
      "\n",
      "Que trata de la primera salida que de su tierra hizo\n",
      "el ingenioso don Quijote\n",
      "\n",
      "Donde se cuenta la graciosa manera que tuvo don\n",
      "Quijote en armarse caballero\n",
      "...\n",
      "Fragmento final:\n",
      " en Ã©stos como en los estraÃ±os reinos''. Y con esto cumplirÃ¡s\n",
      "con tu cristiana profesiÃ³n, aconsejando bien a quien mal te quiere, y yo\n",
      "quedarÃ© satisfecho y ufano de haber sido el primero que gozÃ³ el fruto de\n",
      "sus escritos enteramente, como deseaba, pues no ha sido otro mi deseo que\n",
      "poner en aborrecimiento de los hombres las fingidas y disparatadas\n",
      "historias de los libros de caballerÃ­as, que, por las de mi verdadero don\n",
      "Quijote, van ya tropezando, y han de caer del todo, sin duda alguna. Vale.\n",
      "\n",
      "Fin\n"
     ]
    }
   ],
   "source": [
    "with open(path_to_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK DON QUIJOTE ***\"\n",
    "end_marker   = \"*** END OF THE PROJECT GUTENBERG EBOOK DON QUIJOTE ***\"\n",
    "\n",
    "start_index = full_text.find(start_marker)\n",
    "end_index   = full_text.find(end_marker)\n",
    "\n",
    "if start_index == -1 or end_index == -1:\n",
    "    # Si no se encuentran los marcadores:\n",
    "    print(\"No se han encontrado los marcadores en el texto. Revisa si la URL o el texto han cambiado.\")\n",
    "else:\n",
    "    # Extrae solo la parte que nos interesa\n",
    "    # Sumamos la longitud de start_marker para no quedarnos con la lÃ­nea entera\n",
    "    main_text = full_text[start_index + len(start_marker):end_index]\n",
    "\n",
    "    # Limpiamos espacios o saltos de lÃ­nea excesivos al inicio y final\n",
    "    main_text = main_text.strip()\n",
    "\n",
    "    print(\"Texto principal extraÃ­do. Longitud:\", len(main_text))\n",
    "    print(\"Fragmento inicial:\\n\", main_text[:500])\n",
    "    print(\"...\\nFragmento final:\\n\", main_text[-500:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear el vocabulario de caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vamos a extraer todos los caracteres Ãºnicos del texto. Esto nos permitirÃ¡ construir un vocabulario con el que podamos asignar un ID numÃ©rico a cada carÃ¡cter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres Ãºnicos en el Quijote: 92\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', 'Â¡', 'Â«', 'Â»', 'Â¿', 'Ã', 'Ã‰', 'Ã', 'Ã‘', 'Ã“', 'Ãš', 'Ã ', 'Ã¡', 'Ã©', 'Ã­', 'Ã¯', 'Ã±', 'Ã³', 'Ã¹', 'Ãº', 'Ã¼', 'â€”']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(main_text))\n",
    "print(\"Caracteres Ãºnicos en el Quijote:\", len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapear caracteres a enteros (y viceversa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorizaciÃ³n de caracteres con `StringLookup`\n",
    "\n",
    "Antes de entrenar el modelo, necesitamos transformar el texto en una forma que pueda ser procesada por una red neuronal. Para ello, utilizamos la capa [`StringLookup`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup) de Keras, que convierte caracteres en IDs numÃ©ricos y viceversa.\n",
    "\n",
    "Concretamente:\n",
    "\n",
    "- `ids_from_chars`: mapea cada carÃ¡cter del texto a un nÃºmero entero.\n",
    "- `chars_from_ids`: hace la operaciÃ³n inversa, recuperando el carÃ¡cter original a partir del ID.\n",
    "\n",
    "Este mapeo es fundamental para:\n",
    "- Codificar el texto como secuencias numÃ©ricas que puedan ser entendidas por el modelo.\n",
    "- Convertir las predicciones del modelo (que serÃ¡n tambiÃ©n IDs) de vuelta a texto legible.\n",
    "\n",
    "##### Â¿QuÃ© es `[UNK]`?\n",
    "\n",
    "Cuando usamos `StringLookup`, cualquier carÃ¡cter desconocido que no estÃ© en el vocabulario se asigna por defecto al token `[UNK]` (abreviaciÃ³n de â€œunknownâ€). Esto permite manejar entradas inesperadas o errÃ³neas sin que el modelo falle, aunque lo ideal es que el vocabulario contenga todos los caracteres relevantes del texto.\n",
    "\n",
    "En este caso, como extraemos los caracteres Ãºnicos directamente del texto original del Quijote, **el vocabulario estÃ¡ perfectamente alineado con los datos**, por lo que no deberÃ­amos ver `[UNK]` en la prÃ¡ctica. Aun asÃ­, la capa lo reserva por defecto como una opciÃ³n de seguridad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743934365.966342    5215 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Crear el mapeo de caracteres a IDs\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None\n",
    ")\n",
    "\n",
    "# Crear el mapeo inverso de IDs a caracteres\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
    ")\n",
    "\n",
    "# FunciÃ³n para convertir una secuencia de IDs a texto\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(keras.src.layers.preprocessing.string_lookup.StringLookup,\n",
       " keras.src.layers.preprocessing.string_lookup.StringLookup)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estas capas son muy Ãºtiles porque permiten mantener la trazabilidad entre el texto original y las representaciones numÃ©ricas que procesarÃ¡ el modelo.\n",
    "type(chars_from_ids), type(ids_from_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VisualizaciÃ³n del mapeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar que la codificaciÃ³n y decodificaciÃ³n funcionan correctamente, mostramos un ejemplo sencillo.\n",
    "\n",
    "Esto nos permite ver que:\n",
    "\n",
    "- El texto `\"Don Quijote\"` se convierte en una secuencia de enteros.\n",
    "- Esa secuencia puede ser transformada de nuevo en el texto original, garantizando que el mapeo es bidireccional y preciso.\n",
    "\n",
    "Esta visualizaciÃ³n es Ãºtil como prueba de validaciÃ³n antes de continuar con el preprocesamiento del corpus completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteres: [b'D' b'o' b'n' b' ' b'Q' b'u' b'i' b'j' b'o' b't' b'e']\n",
      "IDs: [25 61 60  2 37 67 56 57 61 66 52]\n",
      "Reconstruido: [b'D' b'o' b'n' b' ' b'Q' b'u' b'i' b'j' b'o' b't' b'e']\n"
     ]
    }
   ],
   "source": [
    "example_chars = tf.constant(list(\"Don Quijote\"))\n",
    "char_ids = ids_from_chars(example_chars)\n",
    "reconstructed = chars_from_ids(char_ids)\n",
    "\n",
    "print(\"Caracteres:\", example_chars.numpy())\n",
    "print(\"IDs:\", char_ids.numpy())\n",
    "print(\"Reconstruido:\", reconstructed.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversiÃ³n del texto completo a IDs y verificaciÃ³n visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos ahora `ids_from_chars` a todo el texto para convertir cada carÃ¡cter en un ID numÃ©rico, generando asÃ­ la secuencia completa que servirÃ¡ como entrada para el modelo.\n",
    "\n",
    "Esto transforma el corpus textual en una serie de nÃºmeros enteros que codifican el texto carÃ¡cter por carÃ¡cter, preservando el estilo y la estructura.\n",
    "\n",
    "- VerificaciÃ³n\n",
    "\n",
    "    Para asegurarnos de que esta conversiÃ³n es correcta:\n",
    "\n",
    "    - Mostramos los primeros 40 caracteres del texto y sus correspondientes IDs.\n",
    "    - Reconstruimos esos IDs de nuevo a texto usando `chars_from_ids`.\n",
    "    - Visualizamos ambos (carÃ¡cter e ID) en una tabla para confirmar que el proceso de codificaciÃ³n y decodificaciÃ³n es simÃ©trico.\n",
    "\n",
    "    Esto es crucial para garantizar que el modelo reciba los datos en el formato correcto, y que luego podamos interpretar sus predicciones sin ambigÃ¼edades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â· Primeros 10 IDs: [26 58  2 56 60 54 52 60 56 61 65 61  2 55 56 51 48 58 54 61  2 51 61 60\n",
      "  2 37 67 56 57 61 66 52  2 51 52  2 58 48  2 33]\n",
      "\n",
      "Â· ReconstrucciÃ³n: El ingenioso hidalgo don Quijote de la M\n"
     ]
    }
   ],
   "source": [
    "# Convertimos el texto completo a una secuencia de IDs (enteros)\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(main_text, input_encoding=\"UTF-8\"))\n",
    "\n",
    "# VerificaciÃ³n rÃ¡pida\n",
    "print(\"Â· Primeros 10 IDs:\", all_ids[:40].numpy())\n",
    "print(\"\\nÂ· ReconstrucciÃ³n:\", text_from_ids(all_ids[:40]).numpy().decode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CarÃ¡cter</th>\n",
       "      <td>E</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "      <td></td>\n",
       "      <td>l</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1  2   3   4   5   6   7   8   9   ...  30  31 32  33  34 35  \\\n",
       "CarÃ¡cter   E   l      i   n   g   e   n   i   o  ...   t   e      d   e      \n",
       "ID        26  58  2  56  60  54  52  60  56  61  ...  66  52  2  51  52  2   \n",
       "\n",
       "          36  37 38  39  \n",
       "CarÃ¡cter   l   a      M  \n",
       "ID        58  48  2  33  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"CarÃ¡cter\": list(main_text[:40]),\n",
    "    \"ID\": all_ids[:40].numpy()\n",
    "})\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear secuencias a partir del texto vectorizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos transformado el texto completo en una secuencia de IDs (`all_ids`).  \n",
    "Ahora necesitamos dividir esa secuencia larga en **subsecuencias de longitud fija**, que representarÃ¡n:\n",
    "\n",
    "- El **input** que le damos al modelo\n",
    "- Y el **target** que esperamos que prediga (el siguiente carÃ¡cter tras cada input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¿CÃ³mo se hace?\n",
    "\n",
    "1. Elegimos un valor de `seq_length`, por ejemplo 250.  \n",
    "2. Tomamos fragmentos consecutivos del tipo:\n",
    "   - Input: los primeros 250 caracteres\n",
    "   - Target: los mismos 250 desplazados una posiciÃ³n hacia adelante\n",
    "\n",
    "    Ejemplo simplificado con `seq_length = 5`:\n",
    "\n",
    "    | Input IDs     | Target IDs    |\n",
    "    |---------------|---------------|\n",
    "    | [1, 2, 3, 4, 5] | [2, 3, 4, 5, 6] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PreparaciÃ³n con `tf.data.Dataset`\n",
    "\n",
    "- TensorFlow nos permite convertir directamente la secuencia de enteros (`all_ids`) en un dataset eficiente usando `tf.data.Dataset.from_tensor_slices()`.  \n",
    "- Luego agrupamos por ventanas de longitud `seq_length + 1`, y usamos una funciÃ³n auxiliar para separar cada fragmento en `(input, target)`.\n",
    "\n",
    "Al final, barajamos y preparamos el dataset en batches para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Input (primeros 50 caracteres):\n",
      "IDs del input: [26 58  2 56 60 54 52 60 56 61]\n",
      "'El ingenioso hidalgo don Quijote de la Mancha\\n\\n\\n\\np'\n",
      "\n",
      "ğŸ”¸ Target (primeros 50 caracteres):\n",
      "IDs del target: [58  2 56 60 54 52 60 56 61 65]\n",
      "'l ingenioso hidalgo don Quijote de la Mancha\\n\\n\\n\\npo'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:12:46.629537: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Longitud de cada secuencia de entrada (puedes cambiarlo)\n",
    "seq_length = 250\n",
    "\n",
    "# Dividimos la secuencia en segmentos de longitud seq_length + 1\n",
    "sequences = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "sequences = sequences.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "# FunciÃ³n que separa input y target\n",
    "def split_input_target(seq):\n",
    "    input_seq = seq[:-1]   # todos excepto el Ãºltimo\n",
    "    target_seq = seq[1:]   # todos excepto el primero\n",
    "    return input_seq, target_seq\n",
    "\n",
    "# Aplicamos la transformaciÃ³n\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# VerificaciÃ³n mÃ¡s clara y acotada\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    input_text = text_from_ids(input_example).numpy().decode(\"utf-8\")\n",
    "    target_text = text_from_ids(target_example).numpy().decode(\"utf-8\")\n",
    "\n",
    "    print(\"ğŸ”¹ Input (primeros 50 caracteres):\")\n",
    "    print(\"IDs del input:\", input_example[:10].numpy())\n",
    "    print(repr(input_text[:50]))\n",
    "    print(\"\\nğŸ”¸ Target (primeros 50 caracteres):\")\n",
    "    print(\"IDs del target:\", target_example[:10].numpy())\n",
    "    print(repr(target_text[:50]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar el dataset para entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Una vez generadas las secuencias `(input, target)`, es hora de preparar el dataset para que pueda ser usado durante el entrenamiento del modelo de forma eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Â¿QuÃ© pasos seguimos?**\n",
    "\n",
    "1. **Mezclar (shuffle)**  \n",
    "    - Esto evita que el modelo aprenda dependencias artificiales del orden original del texto.\n",
    "    - Usamos un bÃºfer grande para garantizar una mezcla adecuada (por ejemplo, 10.000 elementos).\n",
    "\n",
    "2. **Agrupar en batches**  \n",
    "    - Procesamos varios ejemplos a la vez durante el entrenamiento.\n",
    "    - Esto acelera el proceso y permite que el modelo aprenda de patrones en paralelo.\n",
    "\n",
    "3. **Prefetching**  \n",
    "    - Prepara los siguientes batches mientras se entrena con los actuales.\n",
    "    - Mejora el rendimiento y reduce el tiempo de espera entre pasos de entrenamiento.\n",
    "\n",
    "Con esta preparaciÃ³n, el dataset estarÃ¡ optimizado tanto en tÃ©rminos de memoria como de velocidad de procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de batches: 65\n",
      "Shape del input: (128, 250)\n",
      "Shape del target: (128, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:12:47.652088: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# ParÃ¡metros\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# Mezclamos, agrupamos en batches y activamos prefetching\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Dividir el dataset en entrenamiento y validaciÃ³n\n",
    "total_batches = dataset.cardinality().numpy()\n",
    "print(\"Total de batches:\", total_batches)\n",
    "val_batches = total_batches // 10  # 10% para validaciÃ³n\n",
    "val_dataset = dataset.take(val_batches)\n",
    "train_dataset = dataset.skip(val_batches)\n",
    "\n",
    "# Verificamos la estructura final del dataset\n",
    "for input_batch, target_batch in dataset.take(1):\n",
    "    print(\"Shape del input:\", input_batch.shape)\n",
    "    print(\"Shape del target:\", target_batch.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir el modelo RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ya tenemos los datos listos. Ahora construiremos el modelo neuronal que serÃ¡ capaz de **predecir el siguiente carÃ¡cter** dado un fragmento previo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitectura utilizada\n",
    "\n",
    "Definimos el modelo como una subclase de `tf.keras.Model`. EstÃ¡ compuesto por tres capas principales:\n",
    "\n",
    "1. **`Embedding`**  \n",
    "   Convierte IDs de caracteres en vectores densos de dimensiÃ³n fija. Esto permite al modelo aprender representaciones Ãºtiles de cada carÃ¡cter.\n",
    "\n",
    "2. **`GRU` (Gated Recurrent Unit)**  \n",
    "   Capa recurrente que captura relaciones temporales.  \n",
    "   La configuramos con `return_sequences=True` y `return_state=True` para que devuelva toda la secuencia de salidas y el estado final (cuando lo necesitemos).\n",
    "\n",
    "3. **`Dense`**  \n",
    "   Capa de salida que produce una predicciÃ³n de probabilidad para cada carÃ¡cter del vocabulario.\n",
    "\n",
    "### HiperparÃ¡metros\n",
    "\n",
    "- `vocab_size`: cantidad total de caracteres Ãºnicos que reconoce el modelo.\n",
    "- `embedding_dim`: dimensiÃ³n de los vectores de embedding.\n",
    "- `rnn_units`: nÃºmero de neuronas en la GRU.\n",
    "\n",
    "Esta arquitectura, aunque sencilla, es adecuada para generar texto en el estilo del Quijote.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del input: (128, 250)\n",
      "Shape del output: (128, 250, 93)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743934369.957781    5673 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# HiperparÃ¡metros del modelo\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# NÃºmero total de caracteres Ãºnicos (vocabulario del modelo)\n",
    "# Incluye el token especial [UNK] usado por StringLookup\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# DimensiÃ³n de los vectores de embedding (puedes ajustar)\n",
    "embedding_dim = 128\n",
    "\n",
    "# NÃºmero de unidades en la GRU (tamaÃ±o del estado oculto)\n",
    "rnn_units = 1250 \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DefiniciÃ³n del modelo como subclase de tf.keras.Model\n",
    "# ------------------------------------------------------------\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__()  # Inicializa la clase base tf.keras.Model\n",
    "\n",
    "        # Capa de Embedding: transforma cada ID en un vector denso\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=embedding_dim\n",
    "        )\n",
    "\n",
    "        # Capa GRU: procesa secuencias manteniendo memoria a lo largo del tiempo\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            units=rnn_units,\n",
    "            return_sequences=True,  # Devuelve salida en cada paso\n",
    "            return_state=True       # TambiÃ©n devuelve el estado final\n",
    "        )\n",
    "\n",
    "        # Capa densa final: proyecta la salida de la GRU a un vector del tamaÃ±o del vocabulario\n",
    "        self.dense = tf.keras.layers.Dense(units=vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        # 1. Embedding\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        # 2. Procesamiento con GRU\n",
    "        outputs = self.gru(x, initial_state=states, training=training)\n",
    "        if return_state:\n",
    "            x, states = outputs  # Desempaqueta (output_sequence, estado_final)\n",
    "            x = self.dense(x, training=training)\n",
    "            return x, states\n",
    "        else:\n",
    "            x = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "            x = self.dense(x, training=training)\n",
    "            return x\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Creamos una instancia del modelo\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Verificamos la forma de entrada y salida con un batch\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "for input_example_batch, _ in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "# Mostramos la forma esperada\n",
    "print(\"Shape del input:\", input_example_batch.shape)         # (batch_size, seq_length)\n",
    "print(\"Shape del output:\", example_batch_predictions.shape)  # (batch_size, seq_length, vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de predicciÃ³n antes del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Antes de entrenar el modelo, es Ãºtil observar cÃ³mo se comporta al recibir una secuencia de entrada.  \n",
    "Aunque aÃºn no ha aprendido nada Ãºtil, **sÃ­ nos permite verificar** que la arquitectura estÃ¡ funcionando correctamente.\n",
    "\n",
    "Â¿QuÃ© haremos?\n",
    "\n",
    "1. Tomamos una secuencia real del dataset como entrada.\n",
    "2. Pasamos esta secuencia por el modelo.\n",
    "3. Obtenemos las predicciones para cada carÃ¡cter.\n",
    "4. Usamos `tf.random.categorical` para **muestrear** los prÃ³ximos caracteres segÃºn las probabilidades predichas.\n",
    "5. Visualizamos y comparamos los resultados.\n",
    "\n",
    "Este proceso nos ayuda a **entender cÃ³mo genera texto carÃ¡cter a carÃ¡cter**, y servirÃ¡ como referencia visual para comparar mÃ¡s adelante con el modelo ya entrenado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Entrada:\n",
      "  y que todo ha de ser errar\n",
      "vos y perdonaros yo? Pues no lo pensÃ©is, bellaco descomulgado, que sin duda\n",
      "lo estÃ¡s, pues has puesto lengua en la sin par Dulcinea. Â¿Y no sabÃ©is vos,\n",
      "gaÃ±Ã¡n, faquÃ­n, belitre, que si no fuese por el valor que ella infunde e\n",
      "\n",
      "ğŸ¤– PredicciÃ³n (aÃºn sin entrenar):\n",
      " ÃCVJHÃ‘ 3ÃšÃºnmWeÃ±Ã‘Ã©dccjRJÃ¹lÃ­1Ã[UNK]QqhRT]: \n",
      "R5Ã‘ÃNQ!RÂ¿nZyun(LÃ ZQ,Ã¹ÃAPSdÂ«DcÃ¹mÃ¹!5PodÃšÃ¡sBoÂ»1W\n",
      "GÃ‰2UmÃ©Hâ€”A?c\"02il4Ujq)vÃ¡\"xl\n",
      "Ã Ã¯Ã“Ã­EÃšsJ,Ã‰t5nvÃ±Ã“:jbl5?DÃ­Ã±m\"duGNgd6lÂ«Ã±Â¿,MÃXzvG:;RQlCnÃ­;WxpVf'!f6Fâ€”jÃº3yuÃ±Ã¯[UNK]Ã“,:xÃ‰nM.PÃš!Ãºp:6mZ.r)Ãf7.Ã±ZÃ±YJÃ­r0c)(JÂ«zBÃ YÃ27BDD.IXWQheGÃº4qaPAFFÃ¼id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 12:12:51.165766: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Seleccionamos un batch de ejemplo y obtenemos las predicciones\n",
    "# ------------------------------------------------------------\n",
    "for input_example_batch, _ in dataset.take(1):\n",
    "    predictions = model(input_example_batch)  # (batch_size, seq_length, vocab_size)\n",
    "    input_example = input_example_batch[0]    # Tomamos solo una secuencia\n",
    "    prediction_logits = predictions[0]        # Logits predichos para esa secuencia (shape: [seq_length, vocab_size])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Usamos tf.random.categorical para muestrear los prÃ³ximos caracteres\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Para cada paso de la secuencia, elegimos un carÃ¡cter basado en la distribuciÃ³n predicha\n",
    "sampled_indices = tf.random.categorical(prediction_logits, num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Mostramos la entrada y lo que el modelo \"predice\" como prÃ³ximos caracteres\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "input_text = text_from_ids(input_example).numpy().decode(\"utf-8\")\n",
    "predicted_text = text_from_ids(sampled_indices).numpy().decode(\"utf-8\")\n",
    "\n",
    "print(\"ğŸ“ Entrada:\\n\", input_text)\n",
    "print(\"\\nğŸ¤– PredicciÃ³n (aÃºn sin entrenar):\\n\", predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entrada</th>\n",
       "      <th>PredicciÃ³n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>e</td>\n",
       "      <td>Ã‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>o</td>\n",
       "      <td>Ãš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d</td>\n",
       "      <td>Ãº</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>h</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>Ã±</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d</td>\n",
       "      <td>Ã‘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e</td>\n",
       "      <td>Ã©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entrada PredicciÃ³n\n",
       "0                   Ã\n",
       "1        y          C\n",
       "2                   V\n",
       "3        q          J\n",
       "4        u          H\n",
       "5        e          Ã‘\n",
       "6                    \n",
       "7        t          3\n",
       "8        o          Ãš\n",
       "9        d          Ãº\n",
       "10       o          n\n",
       "11                  m\n",
       "12       h          W\n",
       "13       a          e\n",
       "14                  Ã±\n",
       "15       d          Ã‘\n",
       "16       e          Ã©\n",
       "17                  d\n",
       "18       s          c\n",
       "19       e          c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ComparaciÃ³n carÃ¡cter a carÃ¡cter\n",
    "char_comparisons = []\n",
    "\n",
    "for inp, pred in zip(input_text, predicted_text):\n",
    "    char_comparisons.append({\"Entrada\": inp, \"PredicciÃ³n\": pred})\n",
    "\n",
    "# Mostrar en tabla (Ãºtil para detectar patrones o errores)\n",
    "df_comparaciones = pd.DataFrame(char_comparisons)\n",
    "display(df_comparaciones.head(20))  # Muestra las primeras 20 comparaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunciÃ³n de pÃ©rdida y evaluaciÃ³n preliminar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Antes de entrenar el modelo, es importante entender cÃ³mo vamos a evaluar su rendimiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Â¿QuÃ© funciÃ³n de pÃ©rdida usamos?\n",
    "\n",
    "Usamos `SparseCategoricalCrossentropy(from_logits=True)`, una funciÃ³n adecuada cuando:\n",
    "\n",
    "- Tenemos mÃºltiples clases posibles (en este caso, cada carÃ¡cter es una clase).\n",
    "- Nuestras etiquetas (targets) son enteros, no vectores one-hot.\n",
    "- La salida del modelo son **logits** (valores sin aplicar `softmax`).\n",
    "\n",
    "Esta funciÃ³n calcula automÃ¡ticamente el `softmax` y compara las distribuciones resultantes con los targets reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  EvaluaciÃ³n en un batch de ejemplo\n",
    "\n",
    "Vamos a comprobar:\n",
    "\n",
    "1. La forma de las predicciones del modelo.\n",
    "2. El valor medio de la pÃ©rdida en un batch.\n",
    "3. Una mÃ©trica derivada llamada **perplejidad**, que nos da una idea de cuÃ¡n \"incierto\" estÃ¡ el modelo al predecir.\n",
    "\n",
    "**Nota**: Al no estar entrenado aÃºn, esperamos una pÃ©rdida alta y una perplejidad elevada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: (128, 250, 93)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:        4.5327754\n",
      "Perplejidad inicial (sin entrenar): 93.01636\n"
     ]
    }
   ],
   "source": [
    "# 1. FunciÃ³n de pÃ©rdida\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 2. Tomamos un batch de ejemplo del dataset\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    # Pasamos el batch por el modelo\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "# 3. EvaluaciÃ³n de la pÃ©rdida\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "\n",
    "print(\"Prediction shape:\", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:       \", example_batch_mean_loss.numpy())\n",
    "\n",
    "# 4. Perplejidad (opcional, pero informativa)\n",
    "perplexity = tf.exp(example_batch_mean_loss).numpy()\n",
    "print(\"Perplejidad inicial (sin entrenar):\", perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Resultados de la evaluaciÃ³n preliminar\n",
    "\n",
    "- **`Prediction shape: (128, 250, 93)`**\n",
    "\n",
    "  Esto significa que:\n",
    "  \n",
    "  - Tenemos un **batch de 128 ejemplos**.\n",
    "  - Cada ejemplo es una secuencia de **250 caracteres**.\n",
    "  - Para cada paso, el modelo genera una distribuciÃ³n sobre **93 posibles caracteres** (tamaÃ±o del vocabulario).\n",
    "\n",
    "- **`Mean loss: 4.53`**\n",
    "\n",
    "  Es la pÃ©rdida media de predicciÃ³n del modelo sobre el batch.  \n",
    "  Como aÃºn **no ha sido entrenado**, este valor es relativamente alto.\n",
    "\n",
    "- **`Perplejidad: ~93`**\n",
    "\n",
    "  La **perplejidad** es una mÃ©trica derivada de la pÃ©rdida.  \n",
    "  Se interpreta como el nÃºmero \"efectivo\" de opciones que el modelo considera posibles en cada paso.  \n",
    "  En este caso, el modelo predice de forma **casi aleatoria** entre los 93 caracteres del vocabulario.\n",
    "\n",
    "A medida que el entrenamiento avance, esperamos que la perplejidad **disminuya notablemente**, indicando que el modelo se vuelve mÃ¡s \"seguro\" al predecir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar el modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos probado que el modelo produce predicciones y que la funciÃ³n de pÃ©rdida se comporta como esperamos, es momento de compilarlo oficialmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **La funciÃ³n de pÃ©rdida (`loss`)**: \n",
    "  - En este caso, `SparseCategoricalCrossentropy(from_logits=True)`, ya que las salidas son logits sin `softmax`.\n",
    "\n",
    "- **El optimizador (`optimizer`)**:\n",
    "  - Usamos `Adam`, que es robusto y eficaz para tareas de secuencias.\n",
    "\n",
    "- **`run_eagerly=True`**:  \n",
    "  Activamos la ejecuciÃ³n *eager* (paso a paso) para que el modelo se ejecute sin construir una grÃ¡fica estÃ¡tica.  \n",
    "  Esto es muy Ãºtil en proyectos didÃ¡cticos como este porque:\n",
    "  - Facilita la depuraciÃ³n y el seguimiento del flujo.\n",
    "  - Permite imprimir o inspeccionar internamente valores durante el entrenamiento.\n",
    "  - Evita errores cuando se usan modelos personalizados o con `tf.function` no compilados aÃºn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"my_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,904</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       â”‚ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>),     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,175,000</span> â”‚\n",
       "â”‚                                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>))           â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)         â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">116,343</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m11,904\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                       â”‚ ((\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m1250\u001b[0m),     â”‚     \u001b[38;5;34m5,175,000\u001b[0m â”‚\n",
       "â”‚                                 â”‚ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1250\u001b[0m))           â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m93\u001b[0m)         â”‚       \u001b[38;5;34m116,343\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,303,247</span> (20.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,303,247\u001b[0m (20.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,303,247</span> (20.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,303,247\u001b[0m (20.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compilamos el modelo\n",
    "model.compile(optimizer=\"adam\", loss=loss, run_eagerly=True)\n",
    "\n",
    "# Mostramos un resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ya tenemos el modelo compilado. Ahora toca entrenarlo para que aprenda a generar texto \"a lo Cervantes\" a partir del corpus del *Quijote*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Â¿CÃ³mo se entrena este tipo de modelo?`\n",
    "\n",
    "- El modelo recibe una secuencia de entrada (por ejemplo, 250 caracteres).\n",
    "- Intenta predecir el **carÃ¡cter siguiente** en cada paso de la secuencia.\n",
    "- Se ajustan los pesos del modelo para minimizar la diferencia entre lo predicho y la secuencia real (objetivo).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para no perder los avances del modelo, usaremos un **callback** que guarda checkpoints:\n",
    "\n",
    "- **Checkpoint Callback:**  \n",
    "  Guarda el modelo tras cada epoch. Esto nos permite retomar el entrenamiento o generar texto mÃ¡s adelante utilizando un modelo ya entrenado.\n",
    "\n",
    "Adicionalmente, se han incorporado dos callbacks para mejorar el proceso de entrenamiento:\n",
    "\n",
    "- **ReduceLROnPlateau:**  \n",
    "  - Monitorea la pÃ©rdida de validaciÃ³n (`val_loss`).  \n",
    "  - Si no hay mejora en 3 epochs consecutivos, reduce la tasa de aprendizaje a la mitad (factor: 0.5).\n",
    "\n",
    "- **EarlyStopping:**  \n",
    "  - TambiÃ©n se basa en `val_loss`.  \n",
    "  - Detiene el entrenamiento si no hay mejora durante 5 epochs consecutivos, restaurando los mejores pesos obtenidos.\n",
    "\n",
    "El entrenamiento se ha configurado para un mÃ¡ximo de 200 epochs, aunque la combinaciÃ³n de estos callbacks puede finalizarlo antes si se alcanza la convergencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta base donde guardaremos los checkpoints del modelo\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "checkpoint_prefix = f\"{checkpoint_dir}/ckpt_{{epoch}}.weights.h5\"\n",
    "\n",
    "# Definimos el callback para guardar checkpoints\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback para reducir la tasa de aprendizaje si la pÃ©rdida no mejora\n",
    "lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',      # Se monitoriza la mÃ©trica de pÃ©rdida\n",
    "    factor=0.5,          # Se reduce la tasa de aprendizaje a la mitad\n",
    "    patience=3,          # Se espera 5 epochs sin mejora antes de reducir\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Callback para detener el entrenamiento temprano si la pÃ©rdida se estanca\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',      # Se monitoriza la pÃ©rdida\n",
    "    patience=5,          # Se esperan 10 epochs sin mejora para detener el entrenamiento\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Se restauran los mejores pesos al final\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 159ms/step - loss: 3.3825 - val_loss: 2.1969 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 2.1337 - val_loss: 1.9512 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.9023 - val_loss: 1.7642 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.7138 - val_loss: 1.5949 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.5671 - val_loss: 1.4757 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 1.4555 - val_loss: 1.3950 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.3777 - val_loss: 1.3225 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.3146 - val_loss: 1.2711 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.2707 - val_loss: 1.2352 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.2324 - val_loss: 1.2057 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.1974 - val_loss: 1.1693 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 1.1698 - val_loss: 1.1447 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 1.1436 - val_loss: 1.1102 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.1182 - val_loss: 1.0933 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.1002 - val_loss: 1.0712 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.0751 - val_loss: 1.0556 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 1.0526 - val_loss: 1.0342 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 1.0322 - val_loss: 1.0006 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 1.0116 - val_loss: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.9876 - val_loss: 0.9554 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.9677 - val_loss: 0.9478 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.9504 - val_loss: 0.9187 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.9252 - val_loss: 0.9003 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.8981 - val_loss: 0.8699 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.8801 - val_loss: 0.8492 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.8528 - val_loss: 0.8200 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.8276 - val_loss: 0.8000 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.8030 - val_loss: 0.7694 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.7829 - val_loss: 0.7438 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.7525 - val_loss: 0.7155 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.7270 - val_loss: 0.6963 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.7022 - val_loss: 0.6673 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.6758 - val_loss: 0.6396 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.6452 - val_loss: 0.6120 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.6207 - val_loss: 0.5897 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.5980 - val_loss: 0.5635 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.5746 - val_loss: 0.5410 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.5520 - val_loss: 0.5242 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.5302 - val_loss: 0.5003 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.5119 - val_loss: 0.4800 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.4884 - val_loss: 0.4622 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.4721 - val_loss: 0.4494 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.4558 - val_loss: 0.4281 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.4398 - val_loss: 0.4128 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 0.4260 - val_loss: 0.4047 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.4124 - val_loss: 0.3869 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - loss: 0.3983 - val_loss: 0.3789 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.3923 - val_loss: 0.3663 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.3800 - val_loss: 0.3610 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.3692 - val_loss: 0.3482 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 162ms/step - loss: 0.3582 - val_loss: 0.3445 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.3528 - val_loss: 0.3345 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 159ms/step - loss: 0.3440 - val_loss: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.3355 - val_loss: 0.3201 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.3323 - val_loss: 0.3163 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.3254 - val_loss: 0.3090 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.3177 - val_loss: 0.3029 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.3147 - val_loss: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.3072 - val_loss: 0.2950 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.3014 - val_loss: 0.2856 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.2938 - val_loss: 0.2770 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 161ms/step - loss: 0.2866 - val_loss: 0.2729 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.2835 - val_loss: 0.2705 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2838 - val_loss: 0.2706 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.2804 - val_loss: 0.2644 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2775 - val_loss: 0.2617 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2730 - val_loss: 0.2656 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.2727 - val_loss: 0.2602 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2694 - val_loss: 0.2560 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2645 - val_loss: 0.2457 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 154ms/step - loss: 0.2587 - val_loss: 0.2479 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 155ms/step - loss: 0.2568 - val_loss: 0.2406 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 157ms/step - loss: 0.2499 - val_loss: 0.2391 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2492 - val_loss: 0.2389 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.2484 - val_loss: 0.2379 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2479 - val_loss: 0.2370 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2435 - val_loss: 0.2380 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 156ms/step - loss: 0.2446 - val_loss: 0.2316 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2432 - val_loss: 0.2313 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2413 - val_loss: 0.2324 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.2361 - val_loss: 0.2182 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2295 - val_loss: 0.2145 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.2258 - val_loss: 0.2188 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2281 - val_loss: 0.2187 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.2260 - val_loss: 0.2136 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.2286 - val_loss: 0.2161 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.2278 - val_loss: 0.2137 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.2255\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.2257 - val_loss: 0.2158 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.1777 - val_loss: 0.1079 - learning_rate: 5.0000e-04\n",
      "Epoch 90/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.1057 - val_loss: 0.0837 - learning_rate: 5.0000e-04\n",
      "Epoch 91/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0821 - val_loss: 0.0698 - learning_rate: 5.0000e-04\n",
      "Epoch 92/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0706 - val_loss: 0.0627 - learning_rate: 5.0000e-04\n",
      "Epoch 93/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0630 - val_loss: 0.0574 - learning_rate: 5.0000e-04\n",
      "Epoch 94/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0581 - val_loss: 0.0543 - learning_rate: 5.0000e-04\n",
      "Epoch 95/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0549 - val_loss: 0.0516 - learning_rate: 5.0000e-04\n",
      "Epoch 96/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0524 - val_loss: 0.0495 - learning_rate: 5.0000e-04\n",
      "Epoch 97/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0506 - val_loss: 0.0483 - learning_rate: 5.0000e-04\n",
      "Epoch 98/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0486 - val_loss: 0.0466 - learning_rate: 5.0000e-04\n",
      "Epoch 99/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0474 - val_loss: 0.0454 - learning_rate: 5.0000e-04\n",
      "Epoch 100/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0460 - val_loss: 0.0447 - learning_rate: 5.0000e-04\n",
      "Epoch 101/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0452 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 102/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0443 - val_loss: 0.0425 - learning_rate: 5.0000e-04\n",
      "Epoch 103/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0435 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 104/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0429 - val_loss: 0.0414 - learning_rate: 5.0000e-04\n",
      "Epoch 105/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0420 - val_loss: 0.0409 - learning_rate: 5.0000e-04\n",
      "Epoch 106/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0417 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
      "Epoch 107/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0411 - val_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 108/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0407 - val_loss: 0.0393 - learning_rate: 5.0000e-04\n",
      "Epoch 109/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0403 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 110/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0400 - val_loss: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0399 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0396 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0395 - val_loss: 0.0391 - learning_rate: 5.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0394 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0400\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0400 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0381 - val_loss: 0.0355 - learning_rate: 2.5000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0357 - val_loss: 0.0344 - learning_rate: 2.5000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 164ms/step - loss: 0.0348 - val_loss: 0.0341 - learning_rate: 2.5000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0347 - val_loss: 0.0340 - learning_rate: 2.5000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0342 - val_loss: 0.0334 - learning_rate: 2.5000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.0341 - val_loss: 0.0335 - learning_rate: 2.5000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 169ms/step - loss: 0.0341 - val_loss: 0.0326 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0337 - val_loss: 0.0331 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0336 - val_loss: 0.0329 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.0335\n",
      "Epoch 125: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0335 - val_loss: 0.0327 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0329 - val_loss: 0.0318 - learning_rate: 1.2500e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step - loss: 0.0322 - val_loss: 0.0321 - learning_rate: 1.2500e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 179ms/step - loss: 0.0323 - val_loss: 0.0319 - learning_rate: 1.2500e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.0323\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0323 - val_loss: 0.0317 - learning_rate: 1.2500e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0319 - val_loss: 0.0319 - learning_rate: 6.2500e-05\n",
      "Epoch 131/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0316 - val_loss: 0.0311 - learning_rate: 6.2500e-05\n",
      "Epoch 132/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step - loss: 0.0316 - val_loss: 0.0312 - learning_rate: 6.2500e-05\n",
      "Epoch 133/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 188ms/step - loss: 0.0314 - val_loss: 0.0313 - learning_rate: 6.2500e-05\n",
      "Epoch 134/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - loss: 0.0315\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0315 - val_loss: 0.0313 - learning_rate: 6.2500e-05\n",
      "Epoch 135/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0313 - val_loss: 0.0311 - learning_rate: 3.1250e-05\n",
      "Epoch 136/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 170ms/step - loss: 0.0313 - val_loss: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 137/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0312 - val_loss: 0.0309 - learning_rate: 3.1250e-05\n",
      "Epoch 138/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0311 - val_loss: 0.0311 - learning_rate: 3.1250e-05\n",
      "Epoch 139/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0312 - val_loss: 0.0308 - learning_rate: 3.1250e-05\n",
      "Epoch 140/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0310 - val_loss: 0.0307 - learning_rate: 3.1250e-05\n",
      "Epoch 141/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 165ms/step - loss: 0.0311 - val_loss: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 142/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0311\n",
      "Epoch 142: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 171ms/step - loss: 0.0311 - val_loss: 0.0310 - learning_rate: 3.1250e-05\n",
      "Epoch 143/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 166ms/step - loss: 0.0310 - val_loss: 0.0310 - learning_rate: 1.5625e-05\n",
      "Epoch 144/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 167ms/step - loss: 0.0310 - val_loss: 0.0307 - learning_rate: 1.5625e-05\n",
      "Epoch 145/200\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.0309\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 168ms/step - loss: 0.0309 - val_loss: 0.0308 - learning_rate: 1.5625e-05\n",
      "Epoch 145: early stopping\n",
      "Restoring model weights from the end of the best epoch: 140.\n"
     ]
    }
   ],
   "source": [
    "# NÃºmero de epochs a entrenar (puedes ajustar)\n",
    "EPOCHS = 200  # NÃºmero de epochs a entrenar\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, lr_reducer, early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvoluciÃ³n del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento, esperamos observar lo siguiente:\n",
    "\n",
    "- **DisminuciÃ³n de la PÃ©rdida (Loss):**  \n",
    "  La curva de la pÃ©rdida deberÃ­a bajar progresivamente, lo que indica que el modelo estÃ¡ aprendiendo a minimizar el error en sus predicciones.\n",
    "\n",
    "- **ReducciÃ³n de la Perplejidad:**  \n",
    "  La perplejidad es el exponencial de la pÃ©rdida y tambiÃ©n deberÃ­a disminuir. Una perplejidad menor significa que el modelo es mÃ¡s confiado en sus predicciones.\n",
    "\n",
    "- **SeÃ±ales de Estancamiento o Sobreentrenamiento:**  \n",
    "  - Si la pÃ©rdida se estabiliza o aumenta, especialmente en el conjunto de validaciÃ³n, podrÃ­a ser necesario ajustar hiperparÃ¡metros, aÃ±adir regularizaciÃ³n (como Dropout o L2) o incorporar mÃ¡s datos.\n",
    "  - Una divergencia significativa entre la pÃ©rdida de entrenamiento y la de validaciÃ³n es un indicador de overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â· PÃ©rdida final de entrenamiento:     0.0310\n",
      "Â· Perplejidad final de entrenamiento: 1.03\n",
      "Â· PÃ©rdida final de validaciÃ³n:     0.0308\n",
      "Â· Perplejidad final de validaciÃ³n: 1.03\n"
     ]
    }
   ],
   "source": [
    "# Extraemos las mÃ©tricas del historial de entrenamiento\n",
    "loss_values = history.history[\"loss\"]\n",
    "val_loss_values = history.history[\"val_loss\"]\n",
    "\n",
    "# Calculamos la perplejidad tanto para entrenamiento como para validaciÃ³n\n",
    "perplexity_values = [np.exp(l) for l in loss_values]\n",
    "val_perplexity_values = [np.exp(l) for l in val_loss_values]\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "# Graficamos las mÃ©tricas de pÃ©rdida y perplejidad para entrenamiento y validaciÃ³n\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, loss_values, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_loss_values, label=\"Validation Loss\")\n",
    "plt.plot(epochs, perplexity_values, label=\"Train Perplexity\")\n",
    "plt.plot(epochs, val_perplexity_values, label=\"Validation Perplexity\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.title(\"ğŸ“‰ EvoluciÃ³n de la pÃ©rdida y perplejidad\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Mostramos los valores finales de ambas mÃ©tricas\n",
    "print(f\"Â· PÃ©rdida final de entrenamiento:     {loss_values[-1]:.4f}\")\n",
    "print(f\"Â· Perplejidad final de entrenamiento: {perplexity_values[-1]:.2f}\")\n",
    "print(f\"Â· PÃ©rdida final de validaciÃ³n:     {val_loss_values[-1]:.4f}\")\n",
    "print(f\"Â· Perplejidad final de validaciÃ³n: {val_perplexity_values[-1]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneraciÃ³n de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n de la clase OneStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Esta clase encapsula el proceso de generaciÃ³n secuencial de texto, permitiendo generar texto de manera iterativa, carÃ¡cter a carÃ¡cter, a partir de un prompt inicial.\n",
    "\n",
    "Funcionalidad que incorpora:\n",
    "- TokenizaciÃ³n del input (ids_from_chars)\n",
    "\n",
    "- GeneraciÃ³n de logits con el modelo\n",
    "\n",
    "- AplicaciÃ³n de temperatura\n",
    "\n",
    "- Muestreo con tf.random.categorical\n",
    "\n",
    "- MÃ¡scara para evitar tokens [UNK]\n",
    "\n",
    "- DecodificaciÃ³n del output (chars_from_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        # Evitamos generar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # Convertimos caracteres en IDs\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        batch_size = tf.shape(input_ids)[0]\n",
    "\n",
    "        # Ajuste de estado\n",
    "        if states is not None:\n",
    "            # Extraemos si es una tupla de un Ãºnico tensor\n",
    "            if isinstance(states, (tuple, list)) and len(states) == 1:\n",
    "                states = states[0]\n",
    "            # Expandimos si estÃ¡ colapsado\n",
    "            if tf.rank(states) == 1:\n",
    "                states = tf.expand_dims(states, 0)\n",
    "            # Ajustamos al batch size actual\n",
    "            if tf.shape(states)[0] != batch_size:\n",
    "                states = tf.tile(states, [batch_size, 1])\n",
    "\n",
    "        # Llamada al modelo\n",
    "        if states is None:\n",
    "            predicted_logits, new_states = self.model(\n",
    "                input_ids, return_state=True, training=False\n",
    "            )\n",
    "        else:\n",
    "            predicted_logits, new_states = self.model(\n",
    "                input_ids, states=(states,), return_state=True, training=False\n",
    "            )\n",
    "\n",
    "        if isinstance(new_states, (tuple, list)) and len(new_states) == 1:\n",
    "            new_states = new_states[0]\n",
    "\n",
    "        # ğŸ”¥ Ãšltimo paso de la secuencia\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        predicted_logits += self.prediction_mask\n",
    "\n",
    "        # Muestreo\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convertir IDs a texto\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        return predicted_chars, new_states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â¿QuÃ© hace cada parte clave?\n",
    "\n",
    "- `temperature`: controla la **aleatoriedad** de la generaciÃ³n (valores bajos = mÃ¡s predecible, valores altos = mÃ¡s creativo).\n",
    "- `prediction_mask`: evita generar el token `[UNK]`, lo que mejora la calidad.\n",
    "- `generate_one_step`: produce **un carÃ¡cter a la vez**, Ãºtil para construir texto en un bucle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GeneraciÃ³n de texto al estilo Cervantes**\n",
    "\n",
    "AquÃ­ tienes un ejemplo listo para usar. Puedes ajustar el **prompt inicial**, la **temperatura** (creatividad) y la **longitud** del texto generado.\n",
    "\n",
    "\n",
    "#### Sugerencias de parÃ¡metros\n",
    "\n",
    "| Temperatura | Resultado esperado                 |\n",
    "|-------------|-------------------------------------|\n",
    "| `0.5`       | Texto mÃ¡s **estructurado** y seguro |\n",
    "| `0.8`       | Equilibrio entre coherencia y creatividad |\n",
    "| `1.0+`      | Resultados **mÃ¡s locos o poÃ©ticos** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "\n",
      "En un lugar de la Mancha; la cual, con el\n",
      "aposento y acomodado, captÃ³ con Anselmo, y todas partes a tus ojos\n",
      "astanden se irme otra vez, y de nuevo se acabÃ³ la vida. Digo\n",
      "que habÃ­a acabado de hacerle aquella vitura con mucha propriedad y entendimiento\n",
      "para todas las compasidas; y, como no fueron advertidos de las dos que\n",
      "habÃ­an meses, que era un muchacho que las damas en aquella pintada y listimada\n",
      "alguna, adonde se invidiÃ³ don Quijote a la historia de don Quijote de la\n",
      "Mancha, de mis dichos y dos gansamezos, y verÃ¡s como se los hicieron esta carta\n",
      "de sus padres, volviÃ³ a hacer menos cuanto le dijese quÃ© modo de parte de\n",
      "Dulcinea. De su escudero se puso del atrevido y hermosura, y luego dio en\n",
      "su aposento de la caÃ±a, por lo cual don Quijote primero le escucharÃ³ si camina\n",
      "muy aprobada entera, sin perjuicio, sacan sus libros y verdaderas. Hay\n",
      "aquella montaÃ±a es que estaban empresa los dos malandrines historiadores cuanto\n",
      "ensancha, no se entrÃ³ por la puerta a pie por el suelo una principal aquella\n",
      "encantada, con \n"
     ]
    }
   ],
   "source": [
    "# Creamos una instancia del generador\n",
    "one_step_model = OneStep(\n",
    "    model,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "# Prompt inicial\n",
    "start_prompt = \"En un lugar de la Mancha\"\n",
    "states = None\n",
    "next_char = tf.constant([start_prompt])\n",
    "result = [next_char]\n",
    "\n",
    "# Generamos texto carÃ¡cter a carÃ¡cter\n",
    "for _ in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "# Resultado final\n",
    "generated_text = tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n",
    "print(\"Texto generado:\\n\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AnÃ¡lisis de texto generado\n",
    "\n",
    "- **Estilo sintÃ¡ctico y lÃ©xico** muy cervantino:  \n",
    "  Uso de frases extensas, formas como *\"viniese\"*, *\"merced\"*, *\"hubiesen\"*, etc.\n",
    "\n",
    "- **Estructura dialogada**:  \n",
    "  El modelo incluso introduce *guiones* y *diÃ¡logos*, algo que suele aprender por patrÃ³n visual.\n",
    "\n",
    "- **CohesiÃ³n narrativa bÃ¡sica**:  \n",
    "  Aunque hay partes incoherentes, el tono general y la atmÃ³sfera son consistentes con el **Don Quijote original**.\n",
    "\n",
    "Esto confirma que:\n",
    "\n",
    "- El modelo ha **aprendido patrones secuenciales** y estilo.\n",
    "- La RNN (GRU) y el vocabulario funcionan correctamente.\n",
    "- Podemos mejorar aÃºn mÃ¡s aumentando *epochs*, ajustando *temperature*, o explorando *beam search*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generacion de texto con temperature=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "\n",
      "En un lugar de la Mancha, y de la\n",
      "misma manera que el cuerdo en la frente llevo.\n",
      "\n",
      "â€” Â¿Y no sÃ© nada â€”respondiÃ³ Sanchoâ€”; sÃ³lo estaba diciendo entre dos\n",
      "mil suertes y levantados en alguna parte y en consigo con los escados\n",
      "algunos de la ventana, y aun se lo ponde campensamientos. Y asÃ­, le dijo:\n",
      "\n",
      "â€” ParÃ©ceme, seÃ±or caballero andante, que vuestra merced ha profesado una de\n",
      "las mÃ¡s estrechas profesiones que hay en la tierra, y tengo para mÃ­ que aun\n",
      "la de los frailes cartujos no es tan estrecha.\n",
      "\n",
      "â€” Tan estrecha bien podÃ­a â€”dijo Sanchoâ€”, que me trae asimismo de abrirlar y\n",
      "defender toda la informada del mundo, que pueda jurar como aquÃ©lla; que\n",
      "los de la noche me han sacado de aquÃ­ se sustentar; y desta manera harÃ¡ lo menos, yo pensar\n",
      "que es verdad que todo lo que dices es tan valiente y tan desagradecida.\n",
      "Finalmente, ha de ser atadas las promesas de los frailes cargan con quien\n",
      "alcanzares; porque suelen los encantos de la vida, si se entreta, sino que\n",
      "te digo que me den la venganza que los se abriÃ³ habo.\n",
      "\n",
      "Callaba Sanch\n"
     ]
    }
   ],
   "source": [
    "# Creamos una instancia del generador\n",
    "one_step_model = OneStep(\n",
    "    model,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "# Prompt inicial\n",
    "start_prompt = \"En un lugar de la Mancha\"\n",
    "states = None\n",
    "next_char = tf.constant([start_prompt])\n",
    "result = [next_char]\n",
    "\n",
    "# Generamos texto carÃ¡cter a carÃ¡cter\n",
    "for _ in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "# Resultado final\n",
    "generated_text = tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n",
    "print(\"Texto generado:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "\n",
      "En un lugar de la Mancha es mi\n",
      "maleta, harto contra villanos callanos; uno del soldado, asiÃ³ de venta\n",
      "trinco, la rienda. TomÃ©O, el principao de Tote de ser abajo, ya. Yo le levantÃ³ muy comenzÃ³ a\n",
      "Garcilas, La Resonumar en lugar, cuando el hombre hizo sed mentecato; y\n",
      "DÃ¡sgase cuando se le cayeron en una buena pieza; y, tuyo; sepa que no\n",
      "andebo de dolor se le arrancaba el alma.\n",
      "HizcaÃ­do, pues, entre aquella tierra y juitamente, luego habÃ­a\n",
      "salido cancionoslas, al cual decÃ­an: no consentiro quÃ© nadiemo, diego entre el\n",
      "mesmo GrisÃ³lo con el Papa, se le quita y le enmiesen los galeotes; menoscaba rico;\n",
      "pero vi y tan sarÃ© al cautivo, que era la que profesabo. en las\n",
      "manos y pie de escuderos y socapada el aspetur de Quicen. Venga EspaÃ±a, y\n",
      "AmadÃ­s de Maute, ni nosotras fingidas tantos y colas. No le diera aseg,\n",
      "al pie de la lengua n diste, y mÃ¡s cruces escuderos de locura que la Golsema,\n",
      "que traer en la cabeza en el mundo con esta exculpa: que esto imagino\n",
      "y su dolor de los amorosos pensamientos, ejos seÃ±ores que el du\n"
     ]
    }
   ],
   "source": [
    "# Creamos una instancia del generador\n",
    "one_step_model = OneStep(\n",
    "    model,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    temperature=2.0\n",
    ")\n",
    "\n",
    "# Prompt inicial\n",
    "start_prompt = \"En un lugar de la Mancha\"\n",
    "states = None\n",
    "next_char = tf.constant([start_prompt])\n",
    "result = [next_char]\n",
    "\n",
    "# Generamos texto carÃ¡cter a carÃ¡cter\n",
    "for _ in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "# Resultado final\n",
    "generated_text = tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n",
    "print(\"Texto generado:\\n\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneraciÃ³n de texto con `Beam Search`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, generÃ¡bamos texto carÃ¡cter a carÃ¡cter usando muestreo aleatorio con tf.random.categorical. Este enfoque introduce creatividad, pero tambiÃ©n puede generar incoherencias o secuencias menos estructuradas.\n",
    "\n",
    "En esta secciÃ³n, implementamos un enfoque mÃ¡s estructurado y determinista:\n",
    "\n",
    "- Beam Search, una tÃ©cnica que explora mÃºltiples caminos posibles en paralelo para encontrar secuencias mÃ¡s coherentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Â¿QuÃ© es Beam Search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Beam Search es una tÃ©cnica heurÃ­stica que mantiene vivas las k mejores secuencias en cada paso, en lugar de solo una.\n",
    "\n",
    "- Inicio: se parte de un prompt inicial (start_prompt) y un estado nulo.\n",
    "\n",
    "- IteraciÃ³n:\n",
    "\n",
    "    - Se generan predicciones para cada secuencia viva en el beam.\n",
    "\n",
    "    - Se seleccionan las k combinaciones mÃ¡s prometedoras de secuencia + siguiente carÃ¡cter.\n",
    "\n",
    "    - Se calcula la probabilidad acumulada de cada camino.\n",
    "\n",
    "- FinalizaciÃ³n:\n",
    "\n",
    "    - Tras num_steps, se devuelve la secuencia con mayor probabilidad acumulada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ParÃ¡metros clave de la funciÃ³n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`beam_width`:\n",
    "- NÃºmero de secuencias que se mantienen en cada paso.\n",
    "- Un valor mayor permite mÃ¡s exploraciÃ³n, pero tambiÃ©n es mÃ¡s costoso computacionalmente.\n",
    "\n",
    "`temperature`:\n",
    "- Suaviza la distribuciÃ³n de salida.\n",
    "- Valores mÃ¡s altos â†’ mÃ¡s aleatoriedad.\n",
    "- Valores bajos â†’ decisiones mÃ¡s deterministas.\n",
    "\n",
    "`num_steps`:\n",
    "- Longitud total del texto a generar (en nÃºmero de caracteres)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LÃ³gica de generaciÃ³n paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Se parte del **prompt inicial**, convertido a IDs.\n",
    "2. En cada paso:\n",
    "   - Se generan predicciones para todas las secuencias vivas.\n",
    "   - Se seleccionan las mejores combinaciones de secuencias y prÃ³ximos caracteres.\n",
    "3. Al finalizar, se selecciona la mejor secuencia generada segÃºn la probabilidad acumulada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearchGenerator:\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, beam_width=3, temperature=1.0):\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.beam_width = beam_width\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # MÃ¡scara para evitar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate(self, start_prompt, num_steps):\n",
    "        initial_state = None\n",
    "        initial_char = tf.constant([start_prompt])\n",
    "        beams = [(0.0, initial_state, initial_char)]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            all_candidates = []\n",
    "\n",
    "            for log_prob, state, seq in beams:\n",
    "                # Paso 1: Convertimos el prompt a IDs\n",
    "                input_chars = tf.strings.unicode_split(seq, \"UTF-8\")\n",
    "                input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "                # Paso 2: Ajustamos el estado como en OneStep\n",
    "                if state is not None:\n",
    "                    if isinstance(state, (tuple, list)) and len(state) == 1:\n",
    "                        state = state[0]\n",
    "                    if tf.rank(state) == 1:\n",
    "                        state = tf.expand_dims(state, 0)\n",
    "                    if tf.shape(state)[0] != tf.shape(input_ids)[0]:\n",
    "                        state = tf.tile(state, [tf.shape(input_ids)[0], 1])\n",
    "                    model_output = self.model(\n",
    "                        input_ids, states=(state,), return_state=True, training=False\n",
    "                    )\n",
    "                else:\n",
    "                    model_output = self.model(\n",
    "                        input_ids, return_state=True, training=False\n",
    "                    )\n",
    "\n",
    "                logits, new_state = model_output\n",
    "                if isinstance(new_state, (tuple, list)) and len(new_state) == 1:\n",
    "                    new_state = new_state[0]\n",
    "\n",
    "                # Paso 3: Ãšltimo logit + temperatura + mÃ¡scara\n",
    "                logits = logits[:, -1, :] / self.temperature\n",
    "                logits += self.prediction_mask\n",
    "                log_probs = tf.nn.log_softmax(logits)\n",
    "\n",
    "                # Paso 4: top-k predicciones\n",
    "                top_k_log_probs, top_k_ids = tf.math.top_k(log_probs, k=self.beam_width)\n",
    "\n",
    "                for i in range(self.beam_width):\n",
    "                    char_id = top_k_ids[0][i]\n",
    "                    char = self.chars_from_ids(char_id[tf.newaxis])\n",
    "                    new_seq = tf.strings.join([seq, char])\n",
    "                    new_log_prob = log_prob + top_k_log_probs[0][i].numpy()\n",
    "                    all_candidates.append((new_log_prob, new_state, new_seq))\n",
    "\n",
    "            # Paso 5: seleccionar los mejores k candidatos\n",
    "            all_candidates = sorted(all_candidates, key=lambda x: x[0], reverse=True)\n",
    "            beams = all_candidates[:self.beam_width]\n",
    "\n",
    "        # Secuencia mÃ¡s probable\n",
    "        best_sequence = beams[0][2]\n",
    "        return best_sequence.numpy()[0].decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Texto generado con Beam Search:\n",
      "En un lugar de la Mancha; la\n",
      "cual, como vio que de algunos perdones historiador que tengo de vengar\n",
      "sus desventuras, ni aun con los martirios de la pereza, sino volvamos\n",
      "a estorbarlo, que la causa de las malas razones, ordenÃ³ de todos los dos dÃ­as a\n",
      "los hombres. Digo esto, Sancho, porque en mÃ­ uno me hubiera muerto;\n",
      "porque no es bien que los caballeros andantes dan trastroso como vuestra\n",
      "merced, se vee en la silla de Babieca en la silla, de mi cuenta, tanto\n",
      "es el seÃ±or don Quijote, que debe de ser principal y riquezas.\n",
      "\n",
      "â€” No es menester mucho â€”dijo a esta sazÃ³n don Quijoteâ€”, que yo soy de la Mancha,\n",
      "cuyas hojas le entraron a don Quijote y a Sancho, a quien dio los diez escudos\n",
      "desotros.\n",
      "\n",
      "Digo, pues, que los diese en el suelo, y luego conocido y conservando en los\n",
      "moros de lÃ¡grimas y comenzaron a encomendarse a su contrario, y lo mesmo hizo el\n",
      "ausencia de don Quijote, y pusiÃ©ronse a caminar tras el carro. Y la\n",
      "honraba en el suelo, junto al primero que derribÃ³ la\n",
      "mula, a cuya luz le pudo ver don Quijote; y, lle\n"
     ]
    }
   ],
   "source": [
    "beam_generator = BeamSearchGenerator(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    beam_width=5,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = beam_generator.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"ğŸ“ Texto generado con Beam Search:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Texto generado con Beam Search:\n",
      "En un lugar de la Mancha; la\n",
      "cual, como vio que de algunos perdones historiador que tengo de vengar\n",
      "sus desventuras, ni aun con los martirios de la pereza, sino volvamos\n",
      "a estorbarlo, que la causa de las malas razones, ordenÃ³ de todos los dos dÃ­as a\n",
      "los hombres. Digo esto, Sancho, porque bien me servÃ­a desta manera:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CapÃ­tulo XXXIX. Donde el cautivo cuenta su vida y sucesos\n",
      "\n",
      "â€” Â«En un lugar de las MontaÃ±as de LeÃ³n tuvo principio mi linaje, con quien\n",
      "fue mÃ¡s agradecida y liberal la naturaleza que la fortuna, aunque, en la\n",
      "estrecheza de mi deseo, soy don Quijote, que se hallÃ³ en Ã©l una hora, y el\n",
      "cura le habÃ­a prometido que le echare de ver la entena de los reyes, esperaban los\n",
      "mozos de plata; el cual, como llegÃ³ con la duquesa a las piernas de\n",
      "Rocinante y de su rostro, con cuyo suceso que debÃ­a de estar encantado,\n",
      "con las mejores razones que con Ã©l estaban espÃ­rituvemente. En efeto nuestro\n",
      "lugar, tornÃ³ a dar seÃ±ales de saberse y de color todo lo que pasaba, y le\n",
      "pidiÃ³ que la pusiese en cobro, o que se ausent\n"
     ]
    }
   ],
   "source": [
    "beam_generator = BeamSearchGenerator(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    beam_width=3,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = beam_generator.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"ğŸ“ Texto generado con Beam Search:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneraciÃ³n de texto  con `Greedy search`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greedy Search es un enfoque determinista para la generaciÃ³n de texto en el que, en cada paso, se selecciona el token con la mayor probabilidad de manera directa, sin explorar otras alternativas. Esto puede resultar en salidas muy coherentes, aunque a veces menos diversas.\n",
    "\n",
    "#### Â¿QuÃ© es Greedy Search?\n",
    "- **Determinismo:** En cada paso se escoge el token mÃ¡s probable (usando `tf.argmax`), lo que produce resultados predecibles.\n",
    "- **Proceso:** Se parte de un prompt inicial y, en cada iteraciÃ³n, se actualiza la secuencia con el token seleccionado, manteniendo y actualizando el estado del modelo.\n",
    "- **Resultado:** Al finalizar un nÃºmero determinado de pasos, se devuelve la secuencia completa generada.\n",
    "\n",
    "#### ParÃ¡metros Clave\n",
    "- **Temperature:** Ajusta la suavidad de la distribuciÃ³n de probabilidad. Con valores bajos la salida es aÃºn mÃ¡s determinista.\n",
    "- **num_steps:** NÃºmero total de tokens (o caracteres) a generar.\n",
    "- **Estado:** Se actualiza en cada paso para conservar el contexto de la secuencia.\n",
    "\n",
    "#### LÃ³gica de GeneraciÃ³n Paso a Paso\n",
    "1. **Inicio:** Convertir el prompt inicial a IDs y establecer el estado inicial en `None`.\n",
    "2. **IteraciÃ³n:**  \n",
    "   - Pasar la secuencia actual y el estado al modelo para obtener los logits y el nuevo estado.\n",
    "   - Aplicar la temperatura (dividiendo los logits) y sumar una mÃ¡scara (para evitar tokens indeseados, como `[UNK]`).\n",
    "   - Seleccionar el token con la mayor probabilidad usando `tf.argmax`.\n",
    "   - Convertir el token a su representaciÃ³n en texto y aÃ±adirlo a la secuencia.\n",
    "3. **FinalizaciÃ³n:** DespuÃ©s de `num_steps`, unir los tokens generados y devolver el texto final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImplementaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchGenerator:\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, temperature=1.0):\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # MÃ¡scara para evitar generar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        num_skip_ids = int(tf.shape(skip_ids)[0])\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * num_skip_ids,\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate(self, start_prompt, num_steps):\n",
    "        # Convertir el prompt inicial a un tensor\n",
    "        input_text = tf.constant([start_prompt])\n",
    "        state = None\n",
    "        result = [input_text]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            # Convertir el texto actual a IDs\n",
    "            input_chars = tf.strings.unicode_split(input_text, \"UTF-8\")\n",
    "            input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "            # Ajustamos el estado si ya existe\n",
    "            if state is not None:\n",
    "                if isinstance(state, (tuple, list)) and len(state) == 1:\n",
    "                    state = state[0]\n",
    "                if tf.rank(state) == 1:\n",
    "                    state = tf.expand_dims(state, 0)\n",
    "                if tf.shape(state)[0] != tf.shape(input_ids)[0]:\n",
    "                    state = tf.tile(state, [tf.shape(input_ids)[0], 1])\n",
    "                logits, state = self.model(input_ids, states=(state,), return_state=True, training=False)\n",
    "            else:\n",
    "                logits, state = self.model(input_ids, return_state=True, training=False)\n",
    "\n",
    "            # Tomamos el logit del Ãºltimo paso, aplicamos temperatura y mÃ¡scara\n",
    "            logits = logits[:, -1, :] / self.temperature\n",
    "            logits += self.prediction_mask\n",
    "\n",
    "            # Seleccionamos el token con mayor probabilidad (greedy)\n",
    "            next_id = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "            next_char = self.chars_from_ids(next_id)\n",
    "\n",
    "            # Actualizamos el input y acumulamos el resultado\n",
    "            input_text = tf.strings.join([input_text, next_char])\n",
    "            result.append(next_char)\n",
    "\n",
    "        # Convertimos la secuencia generada a string\n",
    "        return tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Texto generado con Greedy Search:\n",
      "En un lugar de la Mancha; la\n",
      "cual, como vio que de algunos perdones historiador que tengo de vengar\n",
      "sus desventuras, ni aun con los martirios de la pereza, sino volvamos a\n",
      "estar solo entre los moros que a mÃ­ y a este rey en dineros en esta grande\n",
      "historia que no quiere decir en ella millares de otro mal a ninguno.\n",
      "\n",
      "â€” Pues lo mesmo â€”dijo don Quijoteâ€” porque no ha sido suya ser emperador, y verÃ¡\n",
      "que se me dÃ© a mÃ­ por ocho dÃ­a, y es de mÃ¡s imaginaciones y\n",
      "demasiadoles cada mes''. Y tÃº, Sancho, cuanto mÃ¡s, habiendo hecho\n",
      "estos dÃ­as que te han de alcanzar el vato.\n",
      "\n",
      "â€” En esta invenciÃ³n de la historia â€”respondiÃ³ Sancho Panzaâ€”, sÃ³lo sÃ© decir que\n",
      "si de las noches vale ostende esta nuestra cÃ©dula y en la opiniÃ³n\n",
      "de don Quijote.\n",
      "\n",
      "â€” AsÃ­ me parece a mÃ­ â€”respondiÃ³ Cardenioâ€”, porque, segÃºn da indicio, Ã©l\n",
      "tiene por cierto que todo lo que estos libros cuentan pasÃ³ ni mÃ¡s ni menos\n",
      "que lo escriben, y no le harÃ¡n creer otra cosa frailes descalzos.\n",
      "â€” MentÃ­s con pie de pagarla se puede y debe de ser â€”respondiÃ³ Sanchoâ€”, porque mi c\n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedySearchGenerator(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = greedy_generator.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"ğŸ“ Texto generado con Greedy Search:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneraciÃ³n de texto  con `Top-k Sampling`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-k Sampling es una tÃ©cnica que, en cada paso, restringe el muestreo al conjunto de los *k* tokens con mayor probabilidad. Este mÃ©todo permite mantener una salida coherente al limitar las opciones a las mÃ¡s probables, pero a la vez introduce diversidad al muestrear de forma aleatoria entre estas opciones.\n",
    "\n",
    "#### Â¿QuÃ© es Top-k Sampling?\n",
    "- **RestricciÃ³n:** En cada paso se consideran Ãºnicamente los *k* tokens con mayores probabilidades.\n",
    "- **Diversidad Controlada:** Aunque se muestrea de forma aleatoria, limitar el conjunto a los *k* mejores candidatos tiende a producir salidas coherentes.\n",
    "- **Proceso:** Se parte del prompt inicial y, en cada iteraciÃ³n, se:\n",
    "  - Genera la distribuciÃ³n de probabilidad para el siguiente token.\n",
    "  - Extrae los *k* tokens con mayor probabilidad.\n",
    "  - Aplica softmax a estos valores para obtener una distribuciÃ³n normalizada.\n",
    "  - Muestrea aleatoriamente un token de este conjunto restringido.\n",
    "  - Actualiza la secuencia y el estado del modelo.\n",
    "\n",
    "#### ParÃ¡metros Clave\n",
    "- **k (Top-k):** NÃºmero de tokens candidatos a considerar en cada paso. Valores moderados (por ejemplo, entre 10 y 20) suelen equilibrar coherencia y diversidad.\n",
    "- **Temperature:** Ajusta la distribuciÃ³n de probabilidades; valores cercanos a 1 mantienen un balance, mientras que valores menores la hacen mÃ¡s determinista.\n",
    "- **num_steps:** NÃºmero total de tokens a generar.\n",
    "- **Estado:** Se actualiza a lo largo de la generaciÃ³n para conservar el contexto.\n",
    "\n",
    "#### LÃ³gica de GeneraciÃ³n Paso a Paso\n",
    "1. **Inicio:** Convertir el prompt inicial a IDs y definir el estado inicial en `None`.\n",
    "2. **IteraciÃ³n:**  \n",
    "   - Alimentar la secuencia actual (junto con el estado, si existe) al modelo para obtener los logits y el nuevo estado.\n",
    "   - Extraer los logits del Ãºltimo token, aplicar la temperatura y la mÃ¡scara.\n",
    "   - Utilizar `tf.math.top_k` para obtener los *k* tokens con mayores probabilidades y sus respectivos valores.\n",
    "   - Calcular la distribuciÃ³n softmax de estos valores y muestrear un token aleatoriamente de entre ellos.\n",
    "   - Convertir el token muestreado a texto y actualizar la secuencia y el estado.\n",
    "3. **FinalizaciÃ³n:** Al completar `num_steps`, unir todos los tokens generados y devolver la secuencia final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImplementaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKSampler:\n",
    "    def __init__(self, model, ids_from_chars, chars_from_ids, k=10, temperature=1.0):\n",
    "        self.model = model\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.k = k\n",
    "        self.temperature = temperature\n",
    "\n",
    "        # MÃ¡scara para evitar generar el token [UNK]\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        num_skip_ids = int(tf.shape(skip_ids)[0])\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            indices=skip_ids,\n",
    "            values=[-float(\"inf\")] * num_skip_ids,\n",
    "            dense_shape=[len(self.ids_from_chars.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    def generate(self, start_prompt, num_steps):\n",
    "        # Inicializamos con el prompt y estado nulo\n",
    "        input_text = tf.constant([start_prompt])\n",
    "        state = None\n",
    "        result = [input_text]\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            # Convertimos el texto actual a IDs\n",
    "            input_chars = tf.strings.unicode_split(input_text, \"UTF-8\")\n",
    "            input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "            # Ajustamos el estado si ya existe\n",
    "            if state is not None:\n",
    "                if isinstance(state, (tuple, list)) and len(state) == 1:\n",
    "                    state = state[0]\n",
    "                if tf.rank(state) == 1:\n",
    "                    state = tf.expand_dims(state, 0)\n",
    "                if tf.shape(state)[0] != tf.shape(input_ids)[0]:\n",
    "                    state = tf.tile(state, [tf.shape(input_ids)[0], 1])\n",
    "                logits, state = self.model(input_ids, states=(state,), return_state=True, training=False)\n",
    "            else:\n",
    "                logits, state = self.model(input_ids, return_state=True, training=False)\n",
    "\n",
    "            # Tomamos los logits del Ãºltimo paso, aplicamos temperatura y mÃ¡scara\n",
    "            logits = logits[:, -1, :] / self.temperature\n",
    "            logits += self.prediction_mask\n",
    "\n",
    "            # Extraemos los top-k tokens\n",
    "            topk_values, topk_ids = tf.math.top_k(logits, k=self.k)\n",
    "            # Convertimos los valores a probabilidades\n",
    "            topk_probs = tf.nn.softmax(topk_values)\n",
    "\n",
    "            # Muestreamos de la distribuciÃ³n top-k (usando logaritmos para estabilidad numÃ©rica)\n",
    "            # tf.random.categorical requiere logits; por ello, aplicamos tf.math.log a topk_probs\n",
    "            sampled = tf.random.categorical(tf.math.log(topk_probs), num_samples=1)\n",
    "            sampled = tf.squeeze(sampled, axis=-1)  # forma: [batch_size] (batch_size=1)\n",
    "\n",
    "            # Obtenemos el token real a partir de topk_ids\n",
    "            selected_token = tf.gather(topk_ids, sampled, axis=1)\n",
    "            next_id = tf.squeeze(selected_token, axis=0)\n",
    "            next_char = self.chars_from_ids(next_id)\n",
    "\n",
    "            # Actualizamos el prompt y acumulamos el resultado\n",
    "            input_text = tf.strings.join([input_text, next_char])\n",
    "            result.append(next_char)\n",
    "\n",
    "        return tf.strings.join(result).numpy()[0].decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Texto generado con Top-k Sampling:\n",
      "En un lugar de la Mancha, de\n",
      "Montemano, colmÃ¡ndole por el gobierno y a las manos, me puso al lecho y dejamos, conservando, y\n",
      "mata, ya por hombre de todo se torna a dormir entrambos. TenÃ­a el viaje conociÃ³ a\n",
      "las Indias, las cuales comprarÃ­an ya conocida, y con voz baja le\n",
      "vendÃ­a, y descubriÃ³ con la mujer de Sancho, y aun la mitad del\n",
      "camino, sin saber lo que don Quijote hacÃ­a servido de darle era de\n",
      "camino, en la pelea, atrevido y malfrejale, todo amor y mozo, ni mucha\n",
      "descolgada en los de la maleta.\n",
      "Como sois el ventero, a quien don Quijote la si, ye\n",
      "doba, por hacerle perfecio de responder que se estaba en Bayzar, que no le\n",
      "desampare.\n",
      "\n",
      "Â»â€” No quiero pagar â€”respondiÃ³ Sanchoâ€” que los presentes estÃ¡n llenas destas siestas, tanta\n",
      "filesicordia hecha y de diamantes, y padÃ© antes caballeros andantes en\n",
      "el diablo, como lo sates; y, por no ser armado caballero, no ponga los poetas\n",
      "que son muchos los pensamientos que en punta de las fueves a la\n",
      "galancha? Â¿QuÃ© mayor traje? Â¡Ea, pues es il pradicario, y Ã©l se la darÃ¡ en\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "topk_sampler = TopKSampler(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    k=10,           # Puedes ajustar k; valores moderados (10-20) suelen dar buena coherencia\n",
    "    temperature=1.0 # Temperatura cercana a 1 para mantener la diversidad\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = topk_sampler.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"ğŸ“ Texto generado con Top-k Sampling:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Texto generado con Top-k Sampling:\n",
      "En un lugar de la Mancha, a\n",
      "quien tocaba una guitarra que la que se dice que se detuviera, y el maestresala pon\n",
      "otros sucesos de aquellos que las tenga y contingea la repÃºblica,\n",
      "porque todos se acomodasen a la maÃ±ana, en que se entretiene.\n",
      "\n",
      "Nuevo este negocio estaba puesta la mano y la conforme a los parientes\n",
      "del bosque, contra el uso de los pies de don Quijote, y ella, la mÃ¡s rara\n",
      "habilidad es que nos libre autendÃ­an a sus camasarnes; las colas, llenos de\n",
      "enemigos, y otras tantas verdades, les dijesen: costumbre en\n",
      "riscones y su escudero, yo me sace a subir sobre una serpiente en que\n",
      "la guerra que aquel a ciento de enamorado. Y si no fuese porque\n",
      "imagino..., Â¿quÃ© digo imagino?, sÃ© muy cierto, que todas estas\n",
      "incomodidades son muy anejas al ejercicio de las armas, aquÃ­ me dejarÃ­a\n",
      "morir de puro enojo.\n",
      "\n",
      "A esto replicÃ³ el escudero:\n",
      "\n",
      "â€” SeÃ±or, ya se sobrÃ³ quisiere, si no han oÃ­do decir voluntad al caso, a quien te\n",
      "tengo puesto en aquella sazÃ³n a cosa de tan grandes es como los demÃ¡s, sino\n",
      "has de ser verdaderas co\n"
     ]
    }
   ],
   "source": [
    "topk_sampler = TopKSampler(\n",
    "    model,\n",
    "    ids_from_chars=ids_from_chars,\n",
    "    chars_from_ids=chars_from_ids,\n",
    "    k=30,           \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "prompt = \"En un lugar de la Mancha\"\n",
    "generated_text = topk_sampler.generate(prompt, num_steps=1000)\n",
    "\n",
    "print(\"ğŸ“ Texto generado con Top-k Sampling:\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
